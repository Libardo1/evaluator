---
title: "Strategic Information Security Risk Analysis"
author: "Evaluator toolkit (https://github.com/davidski/evaluator)"
mainfont: BentonSansRE
output:
  html_document:
    css: styles/html-styles.css
    fig_caption: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
  html_notebook:
    code_folding: hide
    css: styles/html-styles.css
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    fig_caption: yes
    toc: yes
  word_document:
    reference_docx: styles/word-styles-reference.docx
    toc: yes
    toc_depth: '3'
monofont: Inconsolata
subtitle: Evaluator Report Sample
header-includes:
- \usepackage{draftwatermark}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyfoot[C]{Sample - \thepage}
---

```{r setup, include=FALSE}
page_width <- 6  # page width in inches, used for figure scaling
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, cache = FALSE,
                      fig.align = 'center')
                      #fig.width = .95 * page_width)

# try to use pacman to install/load packages, if available
if ("pacman" %in% installed.packages()) {
  pacman::p_load(ggplot2, ggalt, scales, viridis, dplyr, purrr)
  pacman::p_load(magrittr, extrafont)
  pacman::p_load(psych, readr, tidyr, pander)
} else  {
  library(ggplot2)
  library(ggalt)
  library(extrafont)
  library(scales)
  library(viridis)
  library(dplyr)
  library(purrr)
  library(magrittr)
  library(readr)
  library(psych)
  library(tidyr)
  library(pander)
}

panderOptions('table.split.table', Inf) # allow pander to make pages wide
panderOptions('table.alignment.default', function(df)
    ifelse(sapply(df, is.numeric), 'right', 'left'))
panderOptions('big.mark', ",")

knitr::read_chunk("./bin/load_data.R")
knitr::read_chunk("./bin/common_graphs.R")
knitr::read_chunk("./bin/utils.R")
```

```{r load_data, echo = FALSE, message = FALSE}
```

```{r useful_values}
focus_scenarios <- c(51, 11)    # scenarios of particular management interest 

# assign risk tolerance dataframe as vector
risk_tolerance <- risk_tolerances$amount
names(risk_tolerance) <- risk_tolerances$level %>% tolower

# Precalculate the standard order of scenarios (domain, then ID of the scenario)
scenario_order <- results %>% group_by(domain_id, scenario_id) %>% summarise()

# text vector of numbers to English words
numbers <- c("one", "two", "three", "four", "five", "six", "seven", "eight", 
             "nine")
```

```{r enhance_summary_object}
# assign loss tolerance to ALE VaR size
scenario_summary %<>% 
  mutate(annual_tolerance = ifelse(ale_var >= risk_tolerance["high"], 
                                   "High", 
                                   ifelse(ale_var >= risk_tolerance["medium"], "Medium", "Low"))) %>% 
  mutate(annual_tolerance = factor(annual_tolerance, 
                                   levels = c("High", "Medium", "Low"), 
                                   ordered = TRUE)) 
scenario_outliers <- scenario_summary[which(scenario_summary$outlier == TRUE), 
                                      "scenario_id"] %>% unlist %>% unname
```

```{r calculate_max_losses}
```

```{r common_functions}
```

```{r calculate_weak_domains}
```

# Summary

> This report is based upon `r comma(attr(results, "simulation_count"))` 
simulations performed over `r comma(length(unique(results$scenario_id)))` 
risk scenarios and `r nrow(capabilities)` capabilites on 
`r format(attr(results, "generated_on"), "%F %H:%M:%S%z")`.

```{r risk_tolerance_exceedance}
loss_exceedance <- results %>% 
  group_by(simulation) %>% 
  summarize(loss = sum(ale)) %>% 
  mutate(tolerance = ifelse(loss >= risk_tolerance["high"], "High", 
                            ifelse(loss >= risk_tolerance["medium"], "Medium", "Low"))) %>% 
  count(tolerance)
```

Total yearly losses are estimated to exceed the organization's major risk 
threshold (`r dollar(risk_tolerance["high"])`) 
`r percent(ifelse (nrow(filter(loss_exceedance, tolerance=="High"))==0, 0, loss_exceedance[loss_exceedance$tolerance == "High", ]$n / max(results$simulation)))` of the time.

The following table shows the maximum, 95th percentile Value at Risk (VaR), 
mean, and minimum annual losses.

```{r overall_exposure, echo=FALSE}
overall <- results %>% group_by(simulation) %>% 
                     summarize(ale = sum(ale)) %>% select(ale) %>%
                     ungroup
data_frame("Value at Risk" = dollar(quantile(overall$ale, c(0.95))),
           "Maximum Loss" = dollar(max(overall$ale)),
           "Mean Loss" = dollar(mean(overall$ale)),
           "Minimum Loss" = dollar(min(overall$ale))
           ) %>% pander(justify = "right", 
                        caption = paste("Total Annual Loss Exposure"))
```

## Loss Exceedance Curve

The following figure shows the frequency total losses will exceed a given 
threshold during a given year. The 80% line shows that a loss of at least 
`r dollar(quantile(filter(max_loss, outliers==FALSE)$max_loss, .2))` 
occurs every four out of five years without outliers, and at at least 
`r dollar(quantile(filter(max_loss, outliers==TRUE)$max_loss, .2))` 
when the outliers are included.

```{r loss_exceedance_curve, fig.cap="Loss Exceedance Curve"}
max_loss %>% 
  group_by(outliers) %>% 
  by_slice(~ arrange(.x, max_loss) %>% 
             mutate(prob = 1 - percent_rank(max_loss)), .collate = "rows") %>% 
  ggplot(., aes(prob, max_loss, group=outliers)) -> gg
gg <- gg + geom_path()

label_dat <- group_by(max_loss, outliers) %>% summarize(max_loss=max(max_loss)) %>% 
  mutate(text = ifelse(outliers==TRUE, "All Scenarios", "Outliers Excluded"))

# set 80% threshold line
gg <- gg + geom_vline(xintercept = 0.8, color = "red", size = 1) 
gg <- gg + annotate("text", x = 0.8, y = max(max_loss$max_loss), 
                    label = percent(.8), hjust="right")

#gg <- gg + scale_color_viridis(discrete = TRUE, 
#                               labels = c("Excluded", "Included"), 
#                               guide = FALSE)
# add labels at end of each line
gg <- gg + geom_label(data=label_dat, aes(x=0, y=max_loss, label=text), 
                      hjust="right", vjust=0.5, label.size = NA)
#gg <- gg + expand_limits(x=-.10)

gg <- gg + scale_x_reverse(labels = percent)
gg <- gg + scale_y_continuous(labels = dollar_millions)
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + theme(panel.grid.major.x = element_blank())
gg <- gg + labs(x = "Chance of Equal or Greater Loss", y = "Loss", 
                title = "Loss Exceedance Curve",
                caption = "Source: Evaluator toolkit")
gg
```

## Risk By Domain

```{r calculate_domain_impact}
```

The top three domains by loss size are `r domain_impact[[1, "domain"]]`, 
 `r domain_impact[[2, "domain"]]`, and `r domain_impact[[3, "domain"]]`.

```{r domain_impact, echo = FALSE}
mutate_each(domain_impact, funs(dollar), -domain_id, -domain) %>% 
  select("Domain" = domain, 
         "Value at Risk" = var,
         "Maximum" = max, 
         "Mean (Average)" = mean,
         "Minimum" = min,
         "Standard Deviation" = sd) %>% 
  pander(justify = c(rep("left", 1), rep("right", 5)),
                 split.cells = 20,
                 caption = "Annual Loss by Domain")
```

### Simulation Outcomes by Domain 

```{r events_contained_vs_losses}
dat <- control_weakness %>% 
  arrange(desc(loss_events), desc(threat_events)) %>% 
  mutate(domain_id = factor(domain_id, levels = rev(unique(domain_id)),
                            ordered = TRUE)) %>% 
  mutate(contained_events = threat_events - loss_events)

# nudge labels 5% off from the end of the segment
label_nudge = c(max(dat$loss_events) / 20 * -1, max(dat$contained_events) / 20)

# set breakpoints to half of the range
break_locations = c(max(dat$loss_events) / 2 * -1.5, max(dat$contained_events) / 2 * 1.5)

# convert data into tidy-er format
dat <- dat %>% gather(type, events, c(loss_events, contained_events)) %>% 
  mutate(actual_events = events) %>% 
  mutate(events = events + 25000, events = ifelse(type == "loss_events", -1 * events, events)) %>% 
  mutate(nudge = ifelse(type == "loss_events", label_nudge[1], label_nudge[2])) %>% 
  mutate(hjust = ifelse(type == "loss_events", "right", "left")) %>% 
  mutate(full_lab = ifelse(type == "loss_events",
                           sprintf("%s (%s)", comma(actual_events), tc_exceedance),
                           sprintf("%s (%s)", comma(actual_events), diff_exceedance)))

# auto-calculate the limits of the plot
event_range <- range(dat$events) * c(1.4, 1.5)

# graph
gg <- ggplot(dat, aes(x = events, xend = 0, y = domain_id)) -> gg
gg <- gg + geom_segment(aes(yend = domain_id), color = viridis(1))
gg <- gg + geom_point(color = viridis(1), size = 2)
gg <- gg + geom_label(aes(label = full_lab, x = events + nudge, y = domain_id, 
                         hjust = hjust), family = "Museo Sans Cond 300", size = 3,
                      label.size = NA)
gg <- gg + geom_label(aes(x = 0, y = domain_id, label = domain_id), size = 3, 
                      label.size = NA)
gg <- gg + scale_x_continuous(breaks = c(break_locations[1], 0, break_locations[2]), 
                              labels = c("Loss Events", "Domain", "Contained Events"),
                              position = "top",
                              limits = event_range)
gg <- gg + labs(x = NULL, y = NULL, 
                title = "Simulation Outcomes by Domain",
                subtitle = "Losses/Contained with Control Gap/Surplus",
                caption = "Source: Evaluator toolkit")
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid = element_blank())
gg <- gg + theme(axis.text.x = element_text(hjust = .5))
gg <- gg + theme(axis.text.y = element_blank())
gg <- gg + theme(axis.ticks.x = element_blank())
gg <- gg + theme(axis.ticks.y = element_blank())
gg
```

## Top Risk Scenarios

The leading scenarios, measured by value at risk, are:

```{r top_5_risks}
top_n(scenario_summary, 5, ale_var) %>% 
  arrange(desc(ale_var)) %>% 
  left_join(scenarios, by = c("scenario_id" = "scenario_id", 
                              "domain_id" = "domain_id")) %>%
  mutate(ale_var = dollar(ale_var), ale_median = dollar(ale_median)) %>% 
  select("Domain ID" = domain_id, Scenario = scenario, 
         "Median Annual Loss" = ale_median, "Value at Risk" = ale_var) %>% 
  pander(justify = c(rep("left", 2), rep("right", 2)), 
         caption = "Top Five Scenarios by Value at Risk")
```

The full list of evaluated risk scenarios is located in [Appendix A](#scenario_list).

## Key Capability Weaknesses



Threats most frequently overcome the control capabilities, resulting in 
losses, in  the domains of `r control_weakness[[1, "domain"]]`, 
`r control_weakness[[2, "domain"]]`, and `r control_weakness[[3, "domain"]]`.

```{r domain_weakness, echo = FALSE}
select(control_weakness, domain, vuln, tc_exceedance, diff_exceedance) %>% 
  rename("Domain" = domain, 
       "Succesful Threat Events" = vuln,
       "Control Gap" = tc_exceedance,
       "Surplus Control Strength" = diff_exceedance) %>% 
  pander(justify = c("left", "right", "right", "right"), 
                 caption = "Domain Weaknesses")
```



## Focus Risk Scenarios

> Identify any scenarios of particular interest here. By highlighting 
those scenarios in which your decission makers have expressed 
interest (e.g. ransomware), these scenarios can be analyzed without losing 
sight of the overall risk picture.

```{r make_scenario_table, echo=FALSE}
display_scenario_table <- function(scenario_summary, id) {
  filter(scenario_summary, scenario_id == id) %>% 
  summarise(
    "Value at Risk" = dollar(ale_var),
    "Vulnerability (% of events resulting in loss)" = percent(mean_vuln),
    "Mean Control Gap" = percent(mean_tc_exceedance / 100),
    "Maximum Annual Loss" = dollar(ale_max),
    "Median Annual Loss" = dollar(round(ale_median)),
    "Maximum Single Loss" = dollar(sle_max),
    "Median Single Loss" = dollar(round(sle_median))
  ) %>% t %>% pander(justify = c("left", "right"), 
                     emphasize.rownames = FALSE, 
                     caption = paste("Scenario", id, "Overview"))
}
```

### Key Scenario A

Scenario: `r filter(scenarios, scenario_id == focus_scenarios[1]) %>% select(scenario) %>% unlist %>% unname`

```{r scenarioA_details, echo=FALSE}
display_scenario_table(scenario_summary, focus_scenarios[1])
```

### Key Scenario B

Scenario: `r filter(scenarios, scenario_id == focus_scenarios[2]) %>% select(scenario) %>% unlist %>% unname`


```{r scenarioB_details, echo=FALSE}
display_scenario_table(scenario_summary, focus_scenarios[2])
```

## Outliers

Some scenarios have values at risk that are significantly higher than the 
population mean of `r dollar(mean(scenario_summary$ale_var))`. To avoid 
distorting the overall analysis, some sections exclude these outliers. Graphs 
and tables are clearly noted when they display filtered data. The outlier 
scenarios are:

```{r show_outliers}
filter(scenario_summary, outlier == TRUE) %>% 
  left_join(scenarios, by = c("domain_id" = "domain_id", "scenario_id" = "scenario_id")) %>% 
  select(domain_id, scenario_id, scenario, ale_var, ale_median, ale_max) %>% 
  arrange(desc(ale_var)) %>% 
  mutate_at(c("ale_var", "ale_median", "ale_max"), dollar) %>% 
  rename("Domain ID" = domain_id, ID = scenario_id, "Description" = scenario, 
         "Value at Risk" = ale_var,
         "Median" = ale_median, "Maximum" = ale_max) %>% 
  pander(justify=c("left", "right", "left", rep("right", 3)))
```

# Methodology

The security strategic risk assessment process is based upon the industry 
standard OpenFAIR methodology. Expert opinion is polled on the threats, 
capabilities, and probable loss magnitudes associated with key risk scenarios. 
This information is used to create a Monte Carlo model, generating a 
a dollar-quantified risk exposure for each tracked risk.

A Value at Risk (VaR) model is used to rank risks. As VaR is a summary 
statistic (the 95 percentile), different groupings are not directly comparable. 
For instance, the VaR totals for domain summary will not match precisely with 
the VaR total for the simulation, nor will either of those statistics match 
the VaR calculated at the scenario level. VaRs should only be compared at a 
consistent level of grouping.

## Domains

The security program is divided into `r nrow(domains)` domains as a framework 
for systematically reviewing risk. These domains are:

```{r domain_table}
select(domains, "Domain ID" = domain_id, "Domain" = domain) %>%
  arrange(Domain) %>% 
  pander(caption = "Domain Listing", justify = "left", 
         split.cells = c("20%", "80%"))
```

## Capabilities

The security team and key subject matter experts formed a consensus opinion on 
the maturity level of the `r nrow(capabilities)` capabilities 
which make up the `r nrow(domains)` security program domains. The 
team assessed each capability against a five-level capability maturity model 
(patterned after the [CMMI](http://cmmiinstitute.com/) model), 
ranging from initial (level 1) through optimizing (level 5). These capability 
ratings are used to create a distribution of simulated capability effectiveness 
over the course of a year, ranging from 100% (completely effective) to 0% 
(completely ineffective).

The full capabilities catalog, including the ratings assigned, is included as 
[Appendix B](#capabilities_list).

## Risk Scenarios

Each domain of the security program has a list of multiple risk scenarios which 
that portion of program is meant to address. These scenarios consists of:

1. The threat community (e.g. internal workforce members, nature, partners) 
performing the action.
2. The action taken by the threat actor.
3. The program capabilities that resist harm by the threat and actor.
4. The consequences of the action, should it occur.

Working against the scenario list, qualitative ratings are assigned for the 
frequency of the threat acting against the institution, the capabilities of 
the threat, and the size of the loss should the attack overcome the 
security program's capabilities.

```{r scenario_table}
arrange(scenarios, domain_id, scenario_id) %>% 
  mutate(scenario_id = paste(domain_id, scenario_id, sep = " - "), 
         tef = stringi::stri_trans_totitle(tef),
         lm = stringi::stri_trans_totitle(lm)) %>% 
  select("Scenario ID" = scenario_id, "Scenario" = scenario, "Actor" = tcomm, 
         "Action Frequency" = tef, "Impact" = lm) %>% 
  pander(caption = "All Scenarios", justify = "left", split.cells = 20)
```

## Simulation

Each of the qualitative labels is mapped to a set of parameters describing a 
beta pert distribution. These distributions are used to run `r comma(attr(results, "simulation_count"))` 
simulations over each risk scenario. Within a given simulation, a scenario is
evaluated for potential losses using:

1. The number of times the threat actor acts against the organization.
2. The capabilities of the threat actor.
3. The difficulty the relevant controls present to the threat actor. For 
    scenarios which have multiple controls applied, difficulty is the 
    arithmetic mean of all the applicable controls.

This process generates several outputs:

* Threat Events: The number of times per year the threat presents itself
* Loss Events: The number of times the threat results in a loss (the threat 
  overcomes the controls)
* Single Loss Expected (SLE): The size range of individual losses from each 
  loss event
* Annual Loss Expected (ALE): The annualized sum of all individual losses.

Risk is the total annual expected losses across all scenarios within a given 
simulation.

## Assumptions

Each of the mappings from qualitative labels to quantitative parameters is 
displayed below.

```{r, table_helper, echo=FALSE}
create_table <- function(label, id) {
  # pandoc.header(label, level = 3)
  filter(mappings, type == id) %>% select(label, l, ml, h, conf) %>% 
    rowwise() %>% 
    mutate(label = stringi::stri_trans_totitle(label)) %>% 
    mutate(l = ifelse(id == "lm", dollar(l), 
                      ifelse(id == "tef", comma(l), percent(l/100)))) %>% 
    mutate(ml = ifelse(id == "lm", dollar(ml), 
                       ifelse(id == "tef", comma(ml), percent(ml/100)))) %>% 
    mutate(h = ifelse(id == "lm", dollar(h), 
                      ifelse(id == "tef", comma(h), percent(h/100)))) %>% 
    rename("Category" = label, "Low" = l, "Most Likely" = ml, "High" = h, 
           "Confidence" = conf) %>% 
    pander(justify = c("left", rep("right", 4)),
           caption = label)
}
```

### Threat Frequencies

```{r threat_frequencies_table}
create_table("Threat Frequencies", "tef")
```

### Threat Capabilities

```{r threat_capabilities_table}
create_table("Threat Capabilities", "tc")
```

### Control Difficulties

```{r control_difficulties_table}
create_table("Control Difficulties", "diff")
```

### Loss Magnitudes

Loss Magnitudes represent the economic impact when a loss event occurs. Types of 
losses include fines, response costs (notification & ID theft monitoring), 
increased audit scrutiny, restoration costs, etc. Instead of modeling different 
loss types (formally defined as primary and secondary losses), this 
analysis takes an aggregate approach with an absolute upper bound for any 
single loss event at the largest known HIPAA fine of $4.8 million. 

```{r loss_magnitudes_table}
create_table("Loss Magnitudes", "lm")
```

# Recommendations

> Recommendations are left for the analyst to complete. Include security 
improvement (increasing the strength of controls) and analysis improvement 
projects (increase data input quality) projects.

## Project Recommendation

> Document the approved or proposed key risk management projects for the coming 
planning period (typically yearly). These projects should address the findings 
from the simulated scenarios by improving controls, reducing loss impact, or 
transferring risk. Describe each project in terms of its cost versus 
the expected amount of reduced loss exposure. 

- FOO
    + Description
    + Cost
    + Expected Loss Reduction
- BAR
    + Description
    + Cost
    + Expected Loss Reduction
- BAZ
    + Description
    + Cost
    + Expected Loss Reduction
- QUX
    + Description
    + Cost
    + Expected Loss Reduction
- UIER
    + Description 
    + Cost
    + Expected Loss Reduction

## Analysis Improvement Opportunities

> The objective of a risk analysis is to provide better information and to 
reduce uncertainty in making strategic resource allocation decisions. 
As part of this decision process, consider if additional information is 
needed to perform a better risk analysis. Additional data or higher 
confidence data may reduce the variability in your projections.

Typical areas for additional data include:

- Control Effectiveness Refinement - Can we benchmark our controls against other 
organizations or otherwise better understand the maturity of our capabilities?
- Scenario Refinement - Have we clearly identified the threat communities, 
their capabilities and their frequency of action?
- Loss Magnitude Refinement - Can we leverage either our own incident data or 
data publicly (such as the VCDB) or semi-publicly (industry CIRTs) to better 
understand our potential economic losses?

# Supplemental Analysis

Scenarios should be treated based upon size of the value at risk (VaR) 
calculation. Ranking scenarios by VaR creates a prioritized list of scenarios to 
address.

```{r scenarios_ranked_by_var_plot}
scenario_summary %>% arrange(desc(ale_var)) %>% 
  filter(ale_var!=0) %>% 
  mutate(scenario_label = paste0(domain_id, " - ", scenario_id)) %>% 
  top_n(20, ale_var) %>% 
  ggplot(., aes(x = ale_var, y = reorder(scenario_label, ale_var), 
                color = annual_tolerance)) -> gg
gg <- gg + geom_lollipop(horizontal = TRUE, point.size = 3)
#gg <- gg + geom_text(aes(label = dollar_millions(ale_var)), color = "black",  hjust=0)
gg <- gg + scale_x_continuous(labels = dollar_millions)
gg <- gg + scale_color_viridis(discrete = TRUE, drop = FALSE, 
                               breaks=c("Low", "Medium", "High"))
gg <- gg + guides(color = guide_legend(title = "Risk Tolerance", 
                                       override.aes = list(size=5)))
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid.major.y = element_blank())
gg <- gg + labs(x=NULL, y="Scenario ID",
                title="Top Scenarios",
                subtitle="Ranked by Vale at Risk",
                caption="Source: Evaluator toolkit")
gg

```

```{r frequency_and_impact_plot}
gg <- ggplot(scenario_summary, aes(x = loss_events_median, y = sle_mean, 
                                   text = scenario_id))
gg <- gg + geom_point(aes(color = annual_tolerance, size = ale_median))
gg <- gg + geom_text(aes(label=ifelse(annual_tolerance %in% c("High", "Medium"), 
                                      paste0(domain_id, " - ", scenario_id), '')), 
                     hjust = "right", vjust = 0.5, nudge_x = -0.35, size = 3)
gg <- gg + labs(title = "Loss Frequency vs Magnitude",
           subtitle = "All Scenarios",
           x = "Median Events per Year",
           y = "Median Single Event Magnitude")
gg <- gg + scale_x_continuous(labels = comma)
gg <- gg + scale_y_continuous(labels = dollar_millions)
gg <- gg + scale_color_viridis(discrete = TRUE, drop = FALSE)
gg <- gg + scale_size_continuous(labels = dollar_millions)
gg <- gg + guides(size = guide_legend(title = "Median Annual Loss", 
                                      title.position = "top"))
gg <- gg + guides(color = guide_legend(title = "Risk Tolerance", 
                                       title.position = "top", 
                                       override.aes = list(size = 5)))
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid.minor = element_blank())
gg
```

## Loss Frequency

Overall frequency of loss events is displayed at the domain and at the 
scenario level.

### Domain-Level Loss Frequency

The number of loss events a domain experiences is the sum of all of the loss 
events which occur for each scenario. To calculate the domain level loss 
frequency, first summarize all of the events at the simulation level, then 
roll up to the scenario level finally performing domain level aggregations.

```{r prepare_skewness_and_kurtosis}
domain_loss_frequency <- results %>% group_by(domain_id, simulation) %>% 
  summarize(loss_events = sum(loss_events)) %>% 
  ungroup %>% 
  slice_rows("domain_id") %>% 
  by_slice(~ describe(.x$loss_events), .collate = "rows") %>% select(-vars)

if (sum(domain_loss_frequency$Skew <= 0, na.rm = TRUE) == 0) {
  narrative <- paste("All domains are positive skewed,",
                     "indicating loss events are clustered to",
                     "the lower ranges.")
}

names(domain_loss_frequency) <- names(domain_loss_frequency) %>% 
  stringi::stri_trans_totitle()
```

Full descriptive statistics are shown on a domain-level summary of loss events.

```{r display_skew_kurt_table}
pander(domain_loss_frequency, 
       caption = "Loss Events by Domain Summary Statistics") 
```

The following figure shows the density of annualized loss events by domain. `r narrative`

```{r lef_by_domain, fig.cap="Loss Frequency by Domain"}
results %>% group_by(domain_id, simulation) %>%
  summarise(loss_events = sum(loss_events)) %>% 
  ggplot(., aes(x = loss_events)) -> gg
gg <- gg + facet_grid(domain_id ~ ., scales = "free_y", switch = "y")
#gg <- gg + scale_fill_viridis(discrete = TRUE)
gg <- gg + geom_density(fill = viridis(1))
gg <- gg + labs(x = "Loss Events Per Year", 
                y = element_blank(),
                title = "Loss Events",
                subtitle = "All Scenarios Included",
                caption = "Source: Evaluator toolkit")
gg <- gg + theme_evaluator()
gg <- gg + theme(strip.text.y = element_text(angle = 180, hjust=0))
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + theme(axis.ticks.y = element_blank(),
                 axis.text.y = element_blank())
gg
```

### Scenario-Level Loss Frequency

Looking at the number of loss events for each scenario helps identify 
scenarios worth closer scrutiny. A z-score is calculated for each mean loss 
frequency. Scenarios with a z-score of 2 or higher experience, on average, 
more frequent loss events.

The average loss frequency and the associated z-scores, are shown for all 
scenarios with an average loss frequency greater than 0.5 per year.

```{r loss_events_by_scenario_table}
loss_events_by_scenario <- results %>% group_by(scenario_id) %>% 
  summarize(n = mean(loss_events))
loss_events_by_scenario %>% mutate(n_zscore = round(scale(n), 2)) %>% 
  filter(n >= 0.5 ) %>% 
  arrange(desc(n)) %>% 
  select("Loss Events" = n, scenario_id, "Z Score" = n_zscore) %>% 
  left_join(scenarios, by = c("scenario_id" = "scenario_id")) %>% 
  mutate("Scenario ID" = paste0(domain_id, " - ", scenario_id),
         "Mean Loss Events" = comma(round(`Loss Events`))) %>% 
  select(`Scenario ID`, Scenario = scenario, `Mean Loss Events`, `Z Score`) %>% 
  pander(justify=c("left", "left", "right", "right"), 
         emphasize.strong.rows = which(.$`Z Score` > 2), 
         caption = "Scenario Mean Loss Frequency")
```

Note that larger than average loss events does not necessarily imply high risk, 
as the total size of all losses may be small. The size of losses is 
explored in the loss magnitude section. In the following figure, density 
diagrams are displayed for each individual scenario, allowing visual inspection 
of which scenarios occur with higher frequency.

```{r lef_by_scenario, fig.height=7, fig.cap="Loss Frequency by Scenario"}
plot_scenarios_by_domain <- function(x) {
  gg <- ggplot(x, aes(x = loss_events, fill = domain_id))
  gg <- gg + facet_wrap(~paste0(domain_id, " - ",  scenario_id),
                        scales = "free_y", strip.position = "bottom")
  gg <- gg + scale_fill_viridis(discrete = TRUE)
  gg <- gg + geom_density()
  #gg <- gg + scale_y_log10(label = dollar)
  gg <- gg + labs(x = "Loss Frequency", y = NULL,
                  title = "Loss Event Frequency by Scenario",
                  caption = "Source: Evaluator toolkit")
  gg <- gg + theme_evaluator()
  gg <- gg + theme(panel.grid.major = element_blank())
  gg <- gg + theme(panel.grid.minor = element_blank())
  gg <- gg + theme(legend.position = "none")
  gg <- gg + theme(axis.ticks.y = element_blank(),
                   axis.text.x = element_blank(),
                   axis.text.y = element_blank(),
                   strip.text.y = element_blank())
  gg
}

results %>% 
  #filter(!(scenario_id %in% c(scenario_outliers, 57))) %>% 
  mutate(scenario_id = factor(as.character(scenario_id), 
                              levels = scenario_order$scenario_id)) %>%
  arrange(domain_id, scenario_id) %>% 
  plot_scenarios_by_domain(.)
```

## Loss Scenario Distributions

This figure shows the range of expected annual losses (ALE) for each scenario 
which has loss events.

```{r ale_range_by_scenario, fig.height=7, fig.cap="Annual Loss Range by Scenario"}
gg <- results %>% group_by(scenario_id) %>% filter(sum(ale) >0) %>% 
  ggplot(., aes(x = as.character(scenario_id), y = ale))
gg <- gg + facet_wrap(~domain_id, ncol = 4, scales = "free", strip.position = "top")
gg <- gg + stat_boxplot(geom = 'errorbar', width = 0.5)
gg <- gg + geom_boxplot(fill = viridis(1),
                        outlier.color = viridis(1), outlier.alpha = 1/3, 
                        outlier.shape = 16)
gg <- gg + scale_y_continuous(labels = dollar_millions, limits = c(0, NA))
gg <- gg + labs(y = "Scenario ID", x = "Annual Loss Exposure",
                title = "Loss Ranges by Domain and Scenario",
                subtitle = "Outliers Included",
                caption = "Source: Evaluator toolkit")
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + theme(strip.text.y = element_text(angle = 0, hjust = 0))

gg
```

## Overall Risk

This section provides additional analysis into the organization's security risk 
profile.

### Domain Level Risk Concentration

Heatmap of Value at Risk by domain.

```{r domain_heatmap, fig.height=2, fig.width=6.5}
```

This figure shows the range of expected annual losses by domain.

```{r risk_by_domain, fig.cap="Risk by Domain"}

test_position <- domain_summary[[nrow(domain_summary), "domain_id"]]

# plot of all ales
gg <- ggplot(domain_summary, aes(x = domain_id, y = ale + 1))
gg <- gg + geom_hline(aes(yintercept = risk_tolerance["high"]), color = "red") +
  annotate("text", x = test_position, y = risk_tolerance["high"], 
           label = "High", vjust = "bottom", hjust = "right")
gg <- gg + geom_hline(aes(yintercept = risk_tolerance["medium"]), 
                      color = "lightsteelblue") +
  annotate("text", x = test_position, y = risk_tolerance["medium"], 
           label = "Medium", vjust = "bottom", hjust = "right")
gg <- gg + stat_boxplot(geom = 'errorbar', width = 0.5)
gg <- gg + geom_boxplot(fill = viridis(1), alpha = 1/5,
                        outlier.color = "black", outlier.alpha = 1/2,
                        outlier.shape = 16)
#gg <- gg + geom_boxplot(aes(fill = domain_id), alpha = 1/5, outlier.shape = NA)
#gg <- gg + geom_violin(fill = viridis(1), alpha = 1/5)
gg <- gg + scale_y_continuous(labels = dollar_millions)
gg <- gg + labs(x = "Domain", y = "Annual Loss Exposure",
                title = "Range of Annual Losses by Domain",
                subtitle = "Outliers Included",
                caption = "Source: Evaluator toolkit")
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + theme(legend.position = "none")
gg
```

There are `r numbers[length(scenario_outliers)]` domains 
(`r paste(unique(scenario_summary[scenario_summary$scenario_id %in% scenario_outliers, ]$domain_id), collapse=" and ")`) 
with annual loss ranges which far exceed the other scenarios. The domains that 
contain these scenarios are plotted separately to identify the outlying 
scenarios.

```{r risk_for_outlier_domains, fig.cap="Risk for Outliers"}
# box plot for the outlier domains
outlier_domains <- scenario_summary %>% 
  filter(scenario_id %in% scenario_outliers) %>% group_by(domain_id) %>% 
  summarise() %>% ungroup()

#test_position <- tail(outlier_domains, n = 1) %>% select(domain_id) %>% unlist %>% unname
#test_position <- outlier_domains$domain_id
dat <- results %>% filter(domain_id %in% outlier_domains$domain_id) %>% 
  mutate(full_label = paste0(domain_id, " - ", scenario_id)) %>% 
  arrange(full_label)
test_position <- tail(dat, n = 1) %>% select(full_label) %>% unlist %>% unname

gg <- ggplot(dat, aes(x = full_label, y = ale))
#gg <- gg + facet_grid(. ~ domain_id, scales = "free_x", switch = "x")
gg <- gg + stat_boxplot(geom = 'errorbar', width = 0.5)
gg <- gg + geom_boxplot(aes(fill = domain_id), alpha = 1/5)
#gg <- gg + geom_boxplot(aes(fill = domain_id), alpha = 1/5, outlier.shape = NA)
gg <- gg + geom_hline(aes(yintercept = risk_tolerance["high"]), color = "red") +
  annotate("text", x = test_position, y = risk_tolerance["high"], 
           label = "High", vjust = "bottom", hjust = "right")
gg <- gg + geom_hline(aes(yintercept = risk_tolerance["medium"]), 
                      color = "lightsteelblue") +
  annotate("text", x = test_position, y = risk_tolerance["medium"], 
           label = "Medium", vjust = "bottom", hjust = "right")
gg <- gg + scale_fill_viridis(discrete = TRUE)
gg <- gg + scale_y_continuous(labels = dollar_millions)
gg <- gg + labs(x = "Domain / Scenario ID", y = "Annual Loss Exposure", 
                title = "Domain with Outlier Scenarios",
                subtitle = "Single scenarios within domains can dwarf other scenarios",
                caption = "Source: Evaluator toolkit")
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.background = element_blank(),
                 panel.grid = element_blank(),
                 panel.border = element_blank())
gg <- gg + theme(legend.position = "none")
gg
```

### Risk by Domain without Outliers

Repeating the above plot across all the scenarios with the outliers removed 
allows examination of the remaining scenarios without distortion. 

```{r annual_loss_no_outliers, fig.cap="Annual Loss Excluding Outliers"}
gg <- results %>% filter(!scenario_id %in% scenario_outliers) %>% 
  mutate(scenario_id = factor(as.character(scenario_id), 
                              levels = as.character(scenario_order$scenario_id))) %>% 
  arrange(domain_id, scenario_id) %>% ggplot(., aes(x = scenario_id, y = ale))
gg <- gg + facet_grid(~domain_id, scales = "free_x", switch = "x")
gg <- gg + labs(x = NULL, y = "Annual Loss Exposure", 
                title = "Loss Range for Each Scenario by Domain",
                subtitle = "Outliers Excluded",
                caption = "Source: Evaluator toolkit")
gg <- gg + stat_boxplot(geom = "errorbar", width = 0.5)
gg <- gg + geom_boxplot(fill = viridis(1),
                        outlier.color = "black", outlier.size = 1/5, 
                        outlier.alpha = 1/20, outlier.shape = 16)
gg <- gg + scale_y_continuous(labels = dollar_millions)
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + theme(axis.text.x = element_blank())
gg
```

### Alternative Risk Measures

Risk is reported as the 95th percentile Value at Risk measure across 
all of the simulated scenarios (sum of scenario ALEs). While this is generally 
the best representation of an organization's  risk exposure, alternative 
measures are possible. The following graph shows a histogram for all non-zero 
loss events with an overlaid density plot for both the standard VaR and the 
median ALE measure as an alternative.

```{r var_vs_median_plot, fig.cap="VaR vs Median"}
# prepare data and init graph
results %>% group_by(scenario_id, simulation) %>% 
  summarize(ale = sum(ale)) %>% 
  filter(ale > 0) %>% 
  summarize(var = quantile(ale, 0.95), median = median(ale)) %>% 
  gather(measure, value, var:median) -> dat

measure_names <- c(
  "median" = "Median",
  "var" = "Value at Risk"
)

gg <- ggplot(dat, aes(value))

# graph options
gg <- gg + geom_histogram(binwidth = max(gg$data$value) / 50, 
                          aes(y = ..density..),
                          color = "black", fill = viridis(2)[1], alpha = 1/5)
gg <- gg + geom_density(fill=viridis(2)[2], alpha = 1/5)
gg <- gg + facet_wrap(~measure, nrow=2, "free_x", strip.position = "left", labeller = as_labeller(measure_names))
gg <- gg + scale_x_continuous(labels = dollar_millions)
#gg <- gg + scale_y_continuous(labels = comma)
gg <- gg + labs(x = "Loss Size", y = element_blank(), 
                title = "Scenario Level Losses",
                subtitle = "Median vs. Value at Risk Measures",
                caption = "Source: Evaluator toolkit")
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + theme(strip.text.y = element_text(angle = 180, hjust = 0))
gg <- gg + theme(axis.text.y = element_blank())
gg
```

## Special Considerations

### Fragile Scenarios

Fragile scenarios are scenarios where a single control protects against loss. 
While the single control may be effective against the threat community, these 
scenarios should be reviewed to see if additional controls are warranted.

```{r fragile_scenarios}
scenarios %>% left_join(domains, by = c("domain_id" = "domain_id")) %>% 
  rowwise %>% 
  mutate(n_controls = length(stringi::stri_split_fixed(controls, ", ")[[1]])) %>%
  filter(n_controls == 1) %>% 
  arrange(domain_id, scenario_id) %>% 
  mutate("Domain" = paste0(domain, " (", domain_id, ")")) %>% 
  select(Domain, "Scenario ID" = scenario_id, 
         Scenario = scenario) %>% 
  pander(justify = c("left", "left", "left"), 
                 split.cells = c("45%", "5%", "50%"), 
                 caption = "Fragile Scenarios")
```

# Appendicies

Additional details that are of tangential use are included as appendices.

## Appendix A {#scenario_list}

```{r risk_list, echo=FALSE}
left_join(scenarios, scenario_summary, by = c("scenario_id" = "scenario_id",
                                            "domain_id" = "domain_id")) %>% 
  arrange(desc(ale_median), desc(ale_var)) %>% 
  mutate_each(funs(dollar), ale_median, ale_var) %>% 
  mutate("Domain" = paste(domain_id, scenario_id, sep = " - ")) %>% 
  select(Domain,
         "Scenario" = scenario, 
         "Median Annual Loss" = ale_median, 
         "Value at Risk" = ale_var) %>% 
  pander(split.cells = 20, justify = c("left", "left", "right", "right"), 
                 caption = "Scenario List")
```

## Appendix B {#capabilities_list}

```{r capabilities_table}
arrange(capabilities, domain_id, id) %>%
  select("Domain ID" = domain_id, "Capability" = capability, "Maturity" = diff) %>%
  pander(., caption = "Capability Listing", split.cells = c(10, 40, 10), 
         justify = c('left', 'left', 'left'))

```
