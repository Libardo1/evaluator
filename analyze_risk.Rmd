---
title: "SAMPLE Strategic Information Security Risk Analysis"
author: "Evaluator Framework (https://github.com/davidski/evaluator)"
output:
  html_document:
    fig_caption: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    fig_caption: yes
    keep_tex: yes
    toc: yes
    toc_depth: '3'
    monofont: inconsolata
  word_document:
    toc: yes
    toc_depth: '3'
subtitle: Sample Evaluator Report
header-includes:
- \usepackage{draftwatermark}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyfoot[C]{Sample - \thepage}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, cache = TRUE)
# plotting, commas, binning, and color libraries
if ("pacman" %in% installed.packages()) {
  pacman::p_load(ggplot2, scales, hexbin, viridis, dplyr, purrr)
  pacman::p_load(psych, readr, pander)
} else  {
  library(ggplot2)
  library(scales)
  library(hexbin)
  library(viridis)
  library(dplyr)
  library(purrr)
  library(readr)
  library(psych)
  library(pander)
}
```

```{r load_data, echo = FALSE, message = FALSE}
# Simulations and pre-computed summary views are created via the 
# `strat_risk.Rmd` notebook.
results <- readRDS(file = "./data/simulation_results.Rds") # full results
scenario_summary <- readRDS(file = "./data/scenario_summary.Rds")  # scenario level summary
domain_summary <- readRDS(file = "./data/domain_summary.Rds")    # domain level summary

# details on our scenarios
domains <- read_csv("./data/domains.csv") # domain catalog
mappings <- read_csv("./data/qualitative_mappings.csv") # qualitative translations
capabilities <- read_csv("data/capabilities.csv") # i.e. objectives & controls
scenarios <- read_csv("./data/scenarios.csv") %>% mutate(tef = tolower(tef), 
                                                         lm = tolower(lm), 
                                                         tc = tolower(tc))
```

```{r useful_values}
# Precalculate the standard order of scenarios (domain, then ID of the scenario)
scenario_order <- results %>% group_by(domain_id, scenario_id) %>% summarise()
# store the `scenario_id` of manually identified outlier (super large upper 
# risk exposure) scenarios.
scenario_outliers <- c(51, 11)  # visually identified outlier(s)
focus_scenarios <- c(51, 11)    # if there are scenariso of particular interest, 
                                # identify them here (or set to NA)
# a text vector of numbers to english works
numbers <- c("one", "two", "three", "four", "five", "six", "seven", "eight", 
             "nine")
# specify the bounds of our risk tolerances
risk_tolerance <- c("medium" = 10 * 10 ^ 6,
                    "high" = 50 * 10 ^ 6)
```

# Summary

> This report is based upon `r comma(attr(results, "simulation_count"))` 
simulations perfomed over `r comma(length(unique(results$scenario_id)))` 
risk scenarios on `r format(attr(results, "generated_on"), "%b %d, %Y %H:%M:%S")`.

## Aggregate Loss Exposure

Interactions between risk scenarios are not modeled. In lieu of complex 
interactions, the calculated annualized losses for each individual scenario 
are computed to show the distribution of potential losses. The following 
table shows the maximum, 95% percentile, mean, 10th percentile, and minimum 
losses for **any single scenario**. It is possible that multiple scenarios could 
realize losses over the course of a single year resulting in higher total losses.

In portions of this analysis, scenarios which are outliers are excluded. Graphs 
and tables with these exclusions are clearly noted.

```{r overall_exposure, echo=FALSE}
overall <- results %>% group_by(simulation) %>% 
                     summarize(ale = max(ale)) %>% select(ale) %>%
                     ungroup
data_frame("Maximum" = dollar(max(overall$ale)),
           "95th Percentile" = dollar(quantile(overall$ale, c(0.95))),
           "Mean" = dollar(mean(overall$ale)),
           "10th Percentile" = dollar(quantile(overall$ale, c(0.10))),
           "Minimum" = dollar(min(overall$ale))
           ) %>% t %>% pander(justify = "right", 
                                caption = paste("Range of Annual Loss", 
                                                "Exposures Across all",
                                                "Simulations"))
```

```{r calculate_max_losses}
max_loss <- results %>% filter(!scenario_id %in% scenario_outliers) %>%  
  group_by(simulation) %>% 
  summarise(loss = max(ale),
            min_loss = min(ale),
            max_loss = sum(ale)) %>%
  ungroup
max_loss_w_outliers <- results %>% 
  group_by(simulation) %>% 
  summarise(loss = max(ale),
            min_loss = min(ale),
            max_loss = sum(ale)) %>%
  ungroup
```

The following figure shows the frequency a given loss value will be met or 
exceeded during a given year, **excluding outlier scenarios**. The 80% line 
reflects that a loss of no less than `r dollar(quantile(max_loss$loss, .2))` 
occurs every four out of five years. The 80% minimum loss threshold with the 
outliers included is  `r dollar(quantile(max_loss_w_outliers$loss, .2))`

```{r loss_exceedance_curve, fig.cap="Loss Exceedance Curve"}
# generate a sequence between zero and the maximum projected single loss
loss_points <- seq(0, max(max_loss$loss), by = max(max_loss$loss / 50))

# for each point in our range of losses, calculate the probability we'll 
# incure losses greater than that amount
dat <- map_df(loss_points, ~ data_frame(loss = .x, 
                                        prob = sum(max_loss$loss > .x) / 
                                          nrow(max_loss)))

gg <- ggplot(dat, aes(x = prob, y = loss))
gg <- gg + geom_path()
gg <- gg + geom_vline(xintercept = 0.8, color = "gray80", size = 1) + 
  annotate("text", x = 0.8, y = max(max_loss$loss), label = percent(.8),
           hjust = 1, size = 3)
gg <- gg + scale_y_continuous(labels = dollar)
gg <- gg + scale_x_reverse(labels = percent)
gg <- gg + theme_minimal()
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + labs(x = "Chance of Equal or Greater Loss", y = "Loss", 
                title = "Loss Exceedance Curve",
                subtitle = "Excluding Outlier Scenarios")
print(gg)
```

## Largest Areas of Impact

```{r calculate_domain_impact}
domain_impact <- domain_summary %>%
  group_by(domain_id) %>%
  select(domain_id, ale) %>%
  summarize_each(funs(mean, max, sd)) %>%
  arrange(desc(mean)) %>% 
  ungroup %>% 
  left_join(domains, by = c("domain_id" = "domain_id")) %>% 
  mutate(domain = paste0(domain, " (", domain_id, ")"))
```

The top three areas of largest expected loss are `r domain_impact[1, "domain"]`, 
 `r domain_impact[2, "domain"]`, and  `r domain_impact[3, "domain"]`.

```{r domain_impact, echo = FALSE}
mutate_each(domain_impact, funs(dollar), -domain_id, -domain) %>% 
  select("Domain" = domain, 
         "Mean Annual Loss" = mean, "Maximum Annual Loss" = max, 
         "Loss Standard Deviation" = sd) %>% 
  pander(justify = c(rep("left", 1), rep("right", 3)),
                 split.cells = 20,
                 caption = "Impact by Domain")
```

## Key Areas of Capability Weakness

```{r calculate_weak_domains}
control_weakness <- scenario_summary %>% group_by(domain_id) %>% 
  summarize(vuln = round(mean(mean_vuln), 2)) %>% 
  arrange(desc(vuln)) %>% 
  mutate(vuln = percent(vuln)) %>% 
  ungroup()
```

Threats most frequently overcome our capabilities and result in losses in 
the domains of `r control_weakness[1, "domain_id"]`, 
`r control_weakness[2, "domain_id"]`, and `r control_weakness[3, "domain_id"]`.

```{r domain_weakness, echo = FALSE}
rename(control_weakness, "Domain" = domain_id, 
       "Frequency Threat Overcomes Control" = vuln) %>% 
  pander(justify = c("left", "right"), 
                 caption = "Domain Weaknesses")
```

## Key Added Risk Scenarios

> Identify any scenarios of particular interest here. By highlighting scenarios 
of interest (e.g. ransomware) to your decission makers, those scenarios of
key management interest can be analyzed and treated in the context of the 
overall risk picture.

```{r make_scenario_table, echo=FALSE}
display_scenario_table <- function(scenario_summary, id) {
  filter(scenario_summary, scenario_id == id) %>% 
  summarise(
    "Vulnerability (% of events results in loss)" = percent(mean_vuln),
    "Mean Control Gap" = percent(mean_tc_exceedance / 100),
    "Maximum Annual Loss" = dollar(ale_max),
    "Median Annual Loss" = dollar(ale_median),
    "Maximum Single Loss" = dollar(sle_max),
    "Median Single Loss" = dollar(sle_median)
  ) %>% t %>% pander(justify = c("left", "right"), 
                     caption = paste("Scenario", id, "Overview"))
}
```

### Key Scenarios A

Scenario: `r filter(scenarios, scenario_id == focus_scenarios[1]) %>% select(scenario)`

```{r scenarioA_details, echo=FALSE}
display_scenario_table(scenario_summary, focus_scenarios[1])
```

### Key Scenario B

Scenario: `r filter(scenarios, scenario_id == focus_scenarios[2]) %>% select(scenario)`

```{r scenarioB_details, echo=FALSE}
display_scenario_table(scenario_summary, focus_scenarios[2])
```

# Recommendations

> Document the key risk management projects for the coming planning period 
(typically yearly) that are either approved or proposed. These projects 
should address the findings from the simulated scenarios by improving controls, 
reducing loss, or transferring risk. Describe each project in terms of its 
expected cost versus the amount of loss exposure addressed by the control.

## Project Recommendation (TBD)

- FOO
    + Description - 
    + Cost
    + Expected Risk Reduction
- BAR
    + Description - 
    + Cost
    + Expected Risk Reduction
- BAZ
    + Description - 
    + Cost
    + Expected Risk Reduction
- QUX
    + Description -
    + Cost
    + Expected Risk Reduction
- UIER
    + Description - 
    + Cost
    + Expected Risk Reduction
- CORGE
    + Description - 
    + Cost
    + Expected Risk Reduction
- QUUX
    + Description - 
    + Cost -
    + Expected Risk Reduction

## Analysis Improvement Opportunities

Every analysis is imperfect. The point of analysis is to provide better 
information and to reduce uncertainty, not to provide perfect information and 
complete confidence. Attempting to do the latter results in an inability to 
complete the work. Identify gaps in your current data and estimates and call 
out any areas where you wish to improve.

- Control Effectiveness Refinement
- Scenario Refinement
- Loss Magnitude Refinement

# Methodology

The security team strategic risk assessment process is based upon the 
industry standard OpenFAIR methodology. Expert opinion is polled on the threats, 
capabilities, and probable lose magnitudes associated with key risk scenarios. 
This information is used to create a Monte Carlo model which generates a 
a risk exposure quantified in dollars for each tracked risk.

## Capabilities

The security team and key subject matter experts met and formed a consensus 
opinion on the maturity level of the `r nrow(capabilities)` capabilities over 
the `r nrow(unique(domain_summary$domain_id))` security program areas. The 
team assessed each capability against a five point capability maturity model 
(patterned after the [CMMI](http://cmmiinstitute.com/) model), 
ranging from initial (level 1) through optimizing (level 5).

These capability ratings are used to create a distribution of simulated 
capability effectiveness over the course of a year, ranging from 100% 
(completely effective) to 0% (completely ineffective). For scenarios which 
have multiple controls applied, the arithmatic mean across all the 
relevant is used.

## Risk Scenarios

Each domain of the security program has a list of multiple risk scenarios which 
the program is meant to address. These scenarios consists of:

1. The threat community (e.g. internal workforce members, nature, partners) 
performing the action.
2. The action taken by the threat actor.
3. The program capabilities that resist harm by the threat and actor.
4. The consequences of the action, should it occur.

With the scenario list, ratings are created of the probability of the 
threat acting against the institution, the capabilities of the threat, and 
the size of the loss should the attack overcome the capabilities. A beta pert 
distribution is used to model each of these factors.

## Risk Simulation

We ran a Monte Carlo process of (`r comma(attr(results, "simulation_count"))`) 
simulations of each risk scenario against the control strength for the domain 
assigned to the threat scenario. This process generates the following outputs:

* Threat Events: The number of times per year the threat presents itself
* Loss Events: The number of times the threat results in a loss (the threat 
  overcomes the controls)
* Single Loss Expected (SLE): The size range of individual losses from each 
  loss event
* Annual Loss Expected (ALE): The annualized sum of all individual losses.

## Assumptions

Parameters for each of the input distributions are displayed below.

```{r, table_helper, echo=FALSE}
create_table <- function(label, id) {
  # pandoc.header(label, level = 3)
  filter(mappings, type == id) %>% select(label, l, ml, h, conf) %>% 
    rowwise() %>% 
    mutate(label = stringi::stri_trans_totitle(label)) %>% 
    mutate(l = ifelse(id == "lm", dollar(l), 
                      ifelse(id == "tef", comma(l), percent(l/100)))) %>% 
    mutate(ml = ifelse(id == "lm", dollar(ml), 
                       ifelse(id == "tef", comma(ml), percent(ml/100)))) %>% 
    mutate(h = ifelse(id == "lm", dollar(h), 
                      ifelse(id == "tef", comma(h), percent(h/100)))) %>% 
    rename("Category" = label, "Low" = l, "Most Likely" = ml, "High" = h, 
           "Confidence" = conf) %>% 
    pander(justify = c("left", rep("right", 4)),
               caption = paste(label, "table"))
}
```

### Threat Frequencies

```{r}
create_table("Threat Frequencies", "tef")
```

### Threat Capabilities

```{r}
create_table("Threat Capabilities", "tc")
```

### Control Difficulties

```{r}
create_table("Control Difficulties", "diff")
```

### Loss Magnitudes

```{r}
create_table("Loss Magnitudes", "lm")
```

# Exploratory Analysis

## Loss Frequency

Whether a loss occurs is a function of:

1. Number of times a threat actor acts against the organization
2. The capabilities of the threat actor
3. The difficulty the relevant controls present to the threat actor

### Loss Frequency by Domain

```{r prepare_skewness_and_kurtosis}
domain_loss_frequency <- results %>% slice_rows("domain_id") %>% 
  by_slice(~ describe(.x$loss_events), .collate="rows") %>% select(-vars)

if (sum(domain_loss_frequency$Skew<=0, na.rm = TRUE) == 0) {
  narrative <- "All domains are positive skewed, indicating loss events are clustered to the lower ranges."
}

names(domain_loss_frequency) <- names(domain_loss_frequency) %>% stringi::stri_trans_totitle()
pander(domain_loss_frequency, caption = "Loss Events by Domain Summary Statistics")
```

The following figure shows the density of annualized loss events by domain. `r narrative`

```{r lef_by_domain, fig.width = 8, fig.height = 8, fig.cap="Loss Frequency by Domain", echo=FALSE}
results %>% group_by(domain_id, simulation) %>%
  summarise(loss_events = sum(loss_events)) %>% 
  ggplot(., aes(x = loss_events)) -> gg
gg <- gg + facet_grid(domain_id ~ ., scales = "free_y", switch = "y")
#gg <- gg + scale_fill_viridis(discrete = TRUE)
gg <- gg + geom_density(alpha = 1/3, fill = viridis(1))
gg <- gg + labs(x = "Loss Events Per Year", 
                title = "Number of Loss Events by Domain")
gg <- gg + theme_minimal()
gg <- gg + theme(strip.text.y = element_text(angle = 180))
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + theme(axis.ticks.y = element_blank(),
                 axis.text.y = element_blank())
print(gg)
```

### Loss Frequency per Scenario

Looking at the loss events for each individual scenario helps identify 
particular scenarios within each domain worth closer scrutiny. FOO 24 and 
BAZ 38 have a larger than average number of losses.

Note that larger than average loss events does not necessarily imply high risk, 
as the total size of all losses may be small. The size of losses is 
explored in the loss magnitude section.

```{r lef_by_scenario, fig.width = 8, fig.height = 8, fig.cap="Loss Frequency by Scenario", echo=FALSE}
plot_scenarios_by_domain <- function(x) {
  gg <- ggplot(x, aes(x = loss_events, fill = domain_id))
  gg <- gg + facet_wrap(~domain_id + scenario_id,
                        scales = "free_y", strip.position = "bottom")
  gg <- gg + scale_fill_viridis(discrete = TRUE)
  gg <- gg + geom_density(alpha = 1/2)
  #gg <- gg + scale_y_log10(label = dollar)
  gg <- gg + theme_minimal()
  gg <- gg + theme(panel.grid.major = element_blank())
  gg <- gg + theme(panel.grid.minor = element_blank())
  gg <- gg + labs(x = "Loss Frequency",
                  title = "Number of Annual Loss Events by Scenario")
  gg <- gg + theme(legend.position = "none")
  gg <- gg + theme(axis.ticks.y = element_blank(),
                   axis.text.x = element_blank(),
                   axis.text.y = element_blank(),
                   strip.text.y = element_blank())
  print(gg)
}

dat <- results %>% mutate(scenario_id = factor(as.character(scenario_id), 
                                        levels = scenario_order$scenario_id)) %>%
  arrange(domain_id, scenario_id)

plot_scenarios_by_domain(dat)

#sapply(unique(results$domain_id), function(x) { 
#  plot_scenarios_by_domain(r2[r2$domain_id == x, ]) })
```

## Loss Magnitudes

Loss Magnitudes represent the economic impact when a loss materializes. Types of 
losses include fines, response costs (notification & ID theft monitoring), 
increased audit scrutiny, restoration costs, etc. Instead of modeling different 
loss types (formally defined as primary and secondary losses), this 
analysis takes an aggregate approach with an absolute upper bound for any 
single loss event at the largest known HIPAA fine of 4.8M USD. 

### ALE Ranges per Scenario

This figure shows the range of expected annual losses (ALE) for each scenario, 
wit **outliers excluded**.

```{r ale_range_by_scenario, fig.height = 8, fig.width=8, fig.cap="Annual Loss Range by Scenario", echo=FALSE}
gg <- results %>% filter(!scenario_id %in% scenario_outliers) %>% 
  ggplot(., aes(x = as.character(scenario_id), 
                          y = ale + 1))
gg <- gg + facet_wrap(~domain_id, scales = "free_x", strip.position = "bottom")
gg <- gg + stat_boxplot(geom = 'errorbar', width = 0.5)
gg <- gg + geom_boxplot(fill = viridis(1), alpha = 1/5, 
                        outlier.color = viridis(1), outlier.alpha = 1/2, 
                        outlier.shape = 16)
gg <- gg + theme_minimal()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + scale_y_continuous(labels = function(x) { 
  paste0("$", x / 10 ^ 6, "M")})
#gg <- gg + scale_y_continuous(label = dollar)
gg <- gg + labs(x = "Scenario ID", y = "ALE",
                title = "Loss Ranges by Domain and Scenario",
                subtitle = "Outliers excluded")
print(gg)
```

## Risk

Risk is the annualized expected loss across all the scenarios in a domain. 
Within a single domain, risk is capped at the maximum loss scenario within 
that domain. This is a limitation of the interactions between scenarios and 
domains not being defined.

### Risk by Domains

This figure shows the range of expected annual losses by domain. The wider 
portion of each column represents where the losses are more likely to occur. 
For example, the FOO domain has expected losses not to exceed BAR, with 
simulations extending down to zero (no loss).

```{r risk_by_domain, echo=FALSE, fig.cap="Risk by Domain"}

test_position <- domain_summary[[nrow(domain_summary), "domain_id"]]

# plot of all ales
gg <- ggplot(domain_summary, aes(x = domain_id, y = ale + 1))
gg <- gg + geom_hline(aes(yintercept = risk_tolerance["high"]), color = "red") +
  annotate("text", x = test_position, y = risk_tolerance["high"], 
           label = "High", vjust = "bottom", hjust = "right")
gg <- gg + geom_hline(aes(yintercept = risk_tolerance["medium"]), 
                      color = "lightsteelblue") +
  annotate("text", x = test_position, y = risk_tolerance["medium"], 
           label = "Medium", vjust = "bottom", hjust = "right")
gg <- gg + stat_boxplot(geom = 'errorbar', width = 0.5)
gg <- gg + geom_boxplot(fill = viridis(1), alpha = 1/3,
                        outlier.color = "black", outlier.alpha = 1/2,
                        outlier.shape = NA)
#gg <- gg + geom_boxplot(aes(fill = domain_id), alpha = 1/5, outlier.shape = NA)
#gg <- gg + geom_violin(fill = viridis(1), alpha = 1/5)
gg <- gg + theme_minimal()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + theme(legend.position = "none")
gg <- gg + scale_y_continuous(labels = function(x) { 
  paste0("$", x / 10 ^ 6, "M")})
gg <- gg + labs(x = "Domain", y = "Annual Expected Loss",
                title = "Range of Annual Losses by Domain",
                subtitle = "Outliers Included")
print(gg)
```

There are `r numbers[length(scenario_outliers)]` domains 
(`r paste(unique(scenario_summary[scenario_summary$scenario_id %in% scenario_outliers, ]$domain_id), collapse=" and ")`) 
with annual loss ranges which far exceed the other scenarios. The domains that 
contain these scenarios are plotted separately to identify the outlying scenarios.

```{r risk_for_outlier_domains, eval = TRUE, echo=FALSE, fig.cap="Risk for Outliers"}
# box plot for the outlier domains
outlier_domains <- scenario_summary %>% 
  filter(scenario_id %in% scenario_outliers) %>% group_by(domain_id) %>% 
  summarise() %>% ungroup()
gg <- results %>% filter(domain_id %in% outlier_domains$domain_id) %>% 
  ggplot(., aes(x = as.character(scenario_id), y = ale))
gg <- gg + facet_grid(. ~ domain_id, scales = "free_x", switch = "x")
gg <- gg + stat_boxplot(geom = 'errorbar', width = 0.5)
gg <- gg + geom_boxplot(aes(fill = domain_id), alpha = 1/5)
#gg <- gg + geom_boxplot(aes(fill = domain_id), alpha = 1/5, outlier.shape = NA)
gg <- gg + scale_fill_viridis(discrete = TRUE)
gg <- gg + scale_y_continuous(labels = function(x) { 
  paste0("$", x / 10 ^ 6, "M")})
gg <- gg + theme_minimal()
gg <- gg + labs(x = "Domain / Scenario ID", y = "Annual Expected Loss", 
                title = "Illustrating Influences of Outliers on Domain Summaries",
                subtitle = "Outliers can greatly influence dommain summaries")
gg <- gg + theme(panel.background = element_blank(),
                 panel.grid = element_blank(),
                 panel.border = element_blank())
gg <- gg + theme(legend.position = "none")
print(gg)
```

### Filter Out the Outlying Scenarios

Repeating the above plot across all the scenarios with the outliers removed 
allows examination of the remaining scenarios without distortion. 

```{r annual_loss_no_outliers, fig.cap="Annual Loss Excluding Outliers"}
#scenario_order$scenario_id
gg <- results %>% filter(!scenario_id %in% scenario_outliers) %>% 
  mutate(scenario_id = factor(as.character(scenario_id), 
                              levels = as.character(scenario_order$scenario_id))) %>% 
  arrange(domain_id, scenario_id) %>% ggplot(., aes(x = scenario_id, y = ale))
gg <- gg + facet_grid(~domain_id, scales = "free_x", switch = "x")
gg <- gg + labs(x = NULL, y = "Annual Expected Loss", 
                title = "Loss Range for Each Scenario by Domain",
                subtitle = "Outliers Excluded")
gg <- gg + stat_boxplot(geom = 'errorbar', width = 0.5)
gg <- gg + geom_boxplot(fill = viridis(1), alpha = 1/5, 
                        outlier.color = "black", outlier.alpha = 1/40, outlier.shape = 16)
gg <- gg + theme_minimal()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + theme(axis.text.x = element_blank())
gg <- gg + scale_y_continuous(labels = function(x) { 
  paste0("$", x / 10 ^ 6, "M")})
print(gg)
```

## Miscellanious

### Fragile Scenarios

Fragile scenarios are scenarios where a single control protects against loss. 
While the single control may be effective against the threat community, these 
scenarios should be reviewed to see if additional controls are warranted.

```{r fragile_scenarios}
scenarios %>% rowwise %>% 
  mutate(n_controls = length(stringi::stri_split_fixed(controls, ", ")[[1]])) %>%
  filter(n_controls == 1) %>% 
  arrange(domain_id, scenario_id) %>% 
  select("Domain ID" = domain_id, "Scenario ID" = scenario_id, 
         Scenario = scenario) %>% 
  pander(justify = c("left", "left", "left"), 
                 split.cells = c("20%", "20%", "60%"), 
                 caption = "Fragile Scenarios")
```

### Median vs Max ALE

```{r median_vs_max_ale, echo = FALSE, fig.cap="Median vs Maximum Annual Loss"}

# scatter plot of median vs. max ALEs
gg <- ggplot(scenario_summary, aes(x = ale_median, y = ale_max))
gg <- gg + geom_point(position = "jitter", alpha = 1/5, aes(size = loss_events))
#gg <- gg + stat_bin2d(bins = 50) + scale_fill_gradient(low = 'lightblue', high = 'red')
#gg <- gg + stat_binhex(bins = 50) + scale_fill_viridis()
#gg <- gg + geom_text(aes(label = title), size = 4)
gg <- gg + scale_x_log10(labels = dollar)
gg <- gg + scale_y_log10(labels = function(x) { 
  paste0("$", x / 10 ^ 6, "M")})
gg <- gg + expand_limits()
gg <- gg + theme_minimal() 
gg <- gg + scale_size_continuous(labels = comma)
gg <- gg + labs(x = "Median ALE", y = "Maxmium ALE", size = "Loss Event Count", 
                title = "Median vs Maximum Annual Loss", 
                subtitle = "Outliers Included")
gg <- gg + expand_limits(x=-100000000)
print(gg)
```

### Histogram of Median ALEs

```{r median_ale_histogram, echo = FALSE, fig.cap="Median Losses"}
# prepare data an init graph
scenario_summary %>% filter(!scenario_id %in% scenario_outliers) %>% 
  ggplot(., aes(x = ale_median)) -> gg

# graph options
gg <- gg + geom_histogram(binwidth = max(gg$data$ale_median) / 50, 
                          aes(y = ..density..),
                          color = "black", fill = "white")
gg <- gg + geom_density(fill = viridis(1), alpha = 1/5)
gg <- gg + scale_x_continuous(labels = dollar) +
  scale_y_continuous(labels = comma)
gg <- gg + theme_minimal()
gg <- gg + labs(x = "Median Annualized Loss", y = element_blank(), 
                title = "Median Losses",
                subtitle = "Outliers Excluded")
print(gg)
```

### Histogram/Density of All Simulations with Outliers

Histogram of all annual losses, across all scenarios and simulations. Zero 
loss scenarios are **excluded** while outliers are **included**.


```{r density_all, echo = FALSE, fig.cap="Risk Exposure"}
# init graph
results %>% filter(ale != 0) %>% ggplot(., aes(x = ale)) -> gg
binwidth <- max(range(gg$data$ale) / 50)

# graph options
gg <- gg + geom_histogram(boundary = 0, binwidth = binwidth, 
                          color = "white", 
                          fill = viridis(1), alpha = 1/5)
gg <- gg + geom_density(fill = "black", alpha = 1/5, 
                        aes(y = get("binwidth", envir=.GlobalEnv) * ..count..))
gg <- gg + scale_x_continuous(labels = dollar) 
gg <- gg + scale_y_continuous(labels = comma)
gg <- gg + labs(x = "Loss Exposure", 
                y = element_blank(), 
                title = "Risk Exposure",
                subtitle = "Outlier Scenarios Included, Zero Loss Scenarios Excluded")
gg <- gg + theme_minimal()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
#gg <- gg + theme(axis.line.y = element_line(color = "black", size = 0.15))
#gg <- gg + theme(axis.line.x = element_line(color = "black", size = 0.15))
gg <- gg + theme(plot.margin = unit(rep(1, 4), "pt"))
#gg <- gg + geom_point(aes(y=cumloss)) + geom_path(aes <- (y=cumloss, group=1))
print(gg)
```

### Risk Exposure without Outliers

Histogram of all annual losses, across all scenarios and simulations. Zero 
loss scenarios and outliers are **excluded**.

```{r histogram_no_outliers, echo = FALSE, fig.cap="Risk Exposure"}
# prepare data and init graph
results %>% filter(!scenario_id %in% scenario_outliers) %>% 
  filter(ale != 0) %>% 
  ggplot(., aes(x = ale)) -> gg
binwidth <- max(range(gg$data$ale) / 50)

#graph options
gg <- gg + geom_histogram(boundary = 0, binwidth = max(gg$data$ale) / 50, 
                          color = "white", 
                          fill = viridis(1), alpha = 1/5)
gg <- gg + geom_density(fill = "black", alpha = 1/5, 
                        aes(y = get("binwidth", envir=.GlobalEnv) * ..count..))
gg <- gg + scale_x_continuous(labels = dollar) 
gg <- gg + scale_y_continuous(labels = comma)
gg <- gg + labs(x = "Annual Loss", 
                y = "Number of Occurances", 
                title = "Risk Exposure",
                subtitle = "Outliers and Zero Loss Scenarios Excluded")
gg <- gg + theme_minimal()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
#gg <- gg + theme(axis.line.y = element_line(color = "black", size = 0.15))
#gg <- gg + theme(axis.line.x = element_line(color = "black", size = 0.15))
gg <- gg + theme(plot.margin = unit(rep(1, 4), "pt"))
#gg <- gg + geom_point(aes(y=cumloss)) + geom_path(aes <- (y=cumloss, group=1))
print(gg)
```

# Appendix

Full risk scenario listing

```{r risk_list,, echo=FALSE}
left_join(scenarios, scenario_summary, by = c("scenario_id" = "scenario_id",
                                            "domain_id" = "domain_id")) %>% 
  arrange(desc(ale_median), desc(ale_var)) %>% 
  mutate_each(funs(dollar), ale_median, ale_var) %>% 
  select("Domain" = domain_id, 
         "ID" = scenario_id,
         "Scenario" = scenario, 
         "Median Annual Loss" = ale_median, 
         "95% Value at Risk" = ale_var) %>% 
  pander(split.cells = 20, justify = c("left", "left", "left", "right", "right"), 
                 caption = "Threat List")
```