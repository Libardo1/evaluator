---
title: "SAMPLE Strategic Information Security Risk Analysis"
subtitle: "Sample Evaluator Report"
author: "Evaluator Framework (https://github.com/davidski/evaluator)"
output:
  html_document:
    fig_caption: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    fig_caption: yes
    keep_tex: yes
    toc: yes
    toc_depth: '3'
  word_document:
    toc: yes
    toc_depth: '3'
header-includes:
- \usepackage{draftwatermark}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyfoot[C]{Sample - \thepage}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
# plotting, commas, binning, and color libraries
if ("pacman" %in% installed.packages()) {
  pacman::p_load(ggplot2, scales, hexbin, viridis, dplyr, purrr)
  pacman::p_load(readr, pander)
} else  {
  library(ggplot2)
  library(scales)
  library(hexbin)
  library(viridis)
  library(dplyr)
  library(purrr)
  library(readr)
  library(pander)
}
```

```{r load_data, echo = FALSE, message = FALSE}
# Simulations and pre-computed summary views are created via the 
# `strat_risk.Rmd` notebook.
results <- readRDS(file = "./data/simulation_results.Rds") # full results
scenario_summary <- readRDS(file = "./data/scenario_summary.Rds")  # scenario level summary
domain_summary <- readRDS(file = "./data/domain_summary.Rds")    # domain level summary

# details on our scenarios
mappings <- read_csv("./data/qualitative_mappings.csv") # qualitative translations
capabilities <- read_csv("data/capabilities.csv") # i.e. objectives & controls
scenarios <- read_csv("./data/scenarios.csv") %>% mutate(tef = tolower(tef), 
                                                         lm = tolower(lm), 
                                                         tc = tolower(tc))
```

```{r useful_values}
# Precalculate the standard order of scenarios (domain, then ID of the scenario)
scenario_order <- results %>% group_by(domain_id, scenario_id) %>% summarise()
# store the `scenario_id` of manually identified outlier (super large upper 
# risk exposure) scenarios.
scenario_outliers <- c(11, 17)    # visually identified outliers
# a text vector of numbers to english works
numbers <- c("one", "two", "three", "four", "five", "six", "seven", "eight", 
             "nine")
# specify the bounds of our risk tolerances
risk_tolerance <- c("medium" = 20 * 10 ^ 6,
                    "high" = 100 * 10 ^6)
```

# Summary

> This report is based upon `r comma(attr(results, "simulation_count"))` 
simulations perfomed over `r comma(length(unique(results$scenario_id)))` 
risk scenarios on `r format(attr(results, "generated_on"), "%b %d, %Y %H:%M:%S")`.

## Aggregate Loss Exposure

Interactions between risk scenarios are not modeled. In lieu of complex 
interactions, the calculated annualized losses for each individual scenario 
are computed to show the distribution of potential losses. The following 
table shows the maximum, 95% percentile, mean, 10th percentile, and minimum 
losses for **any single scenario**. It is possible that multiple scenarios could 
realize losses over the course of a single year resulting in higher total losses.

```{r overall_exposure, echo=FALSE}
overall <- results %>% group_by(simulation) %>% 
                     summarize(ale = max(ale)) %>% select(ale) %>%
                     ungroup
data_frame("Maximum" = dollar(max(overall$ale)),
           "95th Percentile" = dollar(quantile(overall$ale, c(0.95))),
           "Mean" = dollar(mean(overall$ale)),
           "10th Percentile" = dollar(quantile(overall$ale, c(0.10))),
           "Minimum" = dollar(min(overall$ale))
           ) %>% pander::pander(justify = "right", 
                                caption = paste("Range of Annual Loss", 
                                                "Exposures Across all",
                                                "Simulations"))

```

```{r calculate_max_losses}
max_loss <- results %>% filter(!scenario_id %in% scenario_outliers) %>%  
  group_by(simulation) %>% 
  summarise(loss = max(ale),
            min_loss = min(ale),
            max_loss = sum(ale)) %>%
  ungroup
```

The following figure shows the frequency a given loss value will be met or 
exceeded during a given year. The outlier scenarios are excluded. The 80% line 
reflects that we should expect a loss of 
`r dollar(quantile(max_loss$loss, .2))` or more during four out of five years.

```{r loss_exceedance_curve, fig.cap="Loss Exceedance Curve"}
# generate a sequence between zero and the maximum projected single loss
loss_points <- seq(0, max(max_loss$loss), by = max(max_loss$loss / 50))

# for each point in our range of losses, calculate the probability we'll 
# incure losses greater than that amount
dat <- map_df(loss_points, ~ data_frame(loss = .x, 
                                        prob = sum(max_loss$loss > .x) / 
                                          nrow(max_loss)))

gg <- ggplot(dat, aes(x = prob, y = loss))
gg <- gg + geom_path()
gg <- gg + geom_vline(xintercept = 0.8, color = "gray80", size = 1) + 
  annotate("text", x = 0.8, y = max(max_loss$loss), label = percent(.8),
           hjust = 1, size = 3)
gg <- gg + scale_y_continuous(labels = dollar)
gg <- gg + scale_x_reverse(labels = percent)
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme_minimal()
gg <- gg + labs(x = "Chance of Equal or Greater Loss", y = "Loss", 
                title = "Loss Exceedance Curve")
print(gg)
```

## Largest Areas of Impact

```{r calculate_domain_impact}
domain_impact <- domain_summary %>%
  group_by(domain_id) %>%
  select(domain_id, ale) %>%
  summarize_each(funs(mean, max, sd)) %>%
  arrange(desc(mean)) %>% ungroup
```

The top three areas of largest expected loss are `r domain_impact[1, "domain_id"]`, 
 `r domain_impact[2, "domain_id"]`, and  `r domain_impact[3, "domain_id"]`.

```{r domain_impact, echo = FALSE}
mutate_each(domain_impact, funs(dollar), -domain_id) %>% 
  rename("Domain" = domain_id, "Mean Annual Loss" = mean, 
         "Maximum Annual Loss" = max, "Loss Standard Deviation" = sd) %>% 
  pander::pander(justify = c("left", rep("right", 3)),
                 caption = "Impact by Domain")
```

## Key Areas of Capability Weakness

```{r calculate_weak_domains}
control_weakness <- scenario_summary %>% group_by(domain_id) %>% 
  summarize(vuln = round(mean(mean_vuln), 2)) %>% 
  arrange(desc(vuln)) %>% 
  mutate(vuln = percent(vuln)) %>% 
  ungroup()
```

Threats most frequently overcome our capabilities and result in losses in 
the domains of `r control_weakness[1, "domain_id"]`, 
`r control_weakness[2, "domain_id"]`, and `r control_weakness[3, "domain_id"]`.

```{r domain_weakness, echo = FALSE}
rename(control_weakness, "Domain" = domain_id, 
       "Frequency Threat Overcomes Control" = vuln) %>% 
  pander::pander(justify = c("left", "right"), 
                 caption = "Domain Weaknesses")
```

## Key Added Risk Scenarios

> Identify any scenarios of particular interest here. By highlighting scenarios 
of interest (e.g. ransomware) to your decission makers, those scenarios of
key management interest can be analyzed and treated in the context of the 
overall risk picture.

```{r make_scenario_table, echo=FALSE}
display_scenario_table <- function(scenario_summary, id) {
  filter(scenario_summary, scenario_id == id) %>% 
  summarise(
    "Vulnerability (% of events results in loss)" = percent(mean_vuln),
    "Mean Control Gap" = percent(mean_tc_exceedance / 100),
    "Maximum Annual Loss" = dollar(ale_max),
    "Median Annual Loss" = dollar(ale_median),
    "Maximum Single Loss" = dollar(sle_max),
    "Median Single Loss" = dollar(sle_median)
  ) %>% t %>% pander(justify="right", 
                     caption=paste("Scenario", id, "Overview"))
}
```

### (Scenario A)

SOMETHING INTERESTING ABOUT A KEY REDACTED SCENARIO

```{r scenarioA_details, echo=FALSE}
display_scenario_table(scenario_summary, "1")
```

### REDACTED (Scenario B)

SOMETHING INTERESTING ABOUT A KEY REDACTED SCENARIO

```{r scenarioB_details, echo=FALSE}
display_scenario_table(scenario_summary, "1")
```

## Recommendations

Document the key risk management projects for the coming planning period 
(typically yearly) that are either approved or proposed. These projects 
should address the findings from the simulated scenarios by improving controls 
or reducing loss. Describe each project in terms of its expected cost versus 
the amount of loss exposure addressed by the control.

### Project Recommendation (TBD)

- FOO
    + Description - 
    + Cost
    + Expected Risk Reduction
- BAR
    + Description - 
    + Cost
    + Expected Risk Reduction
- BAZ
    + Description - 
    + Cost
    + Expected Risk Reduction
- QUX
    + Description -
    + Cost
    + Expected Risk Reduction
- UIER
    + Description - 
    + Cost
    + Expected Risk Reduction
- CORGE
    + Description - 
    + Cost
    + Expected Risk Reduction
- QUUX
    + Description - 
    + Cost -
    + Expected Risk Reduction

### Analysis Improvement Opportunities

Every analysis is imperfect. The point of analysis is to provide better 
information and to reduce uncertainty, not to provide perfect information and 
complete confidence. Attempting to do the latter results in an inability to 
complete the work. Identify gaps in your current data and estimates and call 
out any areas where you wish to improve.

- Control Effectiveness Refinement
- Scenario Refinement
- Loss Magnitude Refinement

# Methodology

The security team strategic risk assessment process is based upon the 
industry standard OpenFAIR methodology. Expert opinion is polled on the threats, 
capabilities, and probable lose magnitudes associated with key risk scenarios. 
This information is used to create a Monte Carlo model which generates a 
a risk exposure quantified in terms of dollars for each  tracked risk.

## Capabilities

The security function and key subject matter experts met and formed a consensus 
opinion on the maturity level of the `r nrow(capabilities)` capabilities over 
the `r nrow(unique(domain_summary$domain_id))` security program areas. The 
team assessed each capability on a 1-5 capability maturity model, ranging from 
initial (level 1) through optimizing (level 5). For each valuation, notes were 
taken on key observations supporting those  decisions.

These capability mappings are used to create a distribution of actual 
capability effectiveness over the course of a year, ranging from 100% 
(completely effective) to 0% (completely ineffective). When a scenario has
multiple controls associated with the risk statement, the asthmatic mean across 
the simulated effectiveness of all controls is used.

## Risk Scenarios

Each domain of the security program has a list of multiple risk scenarios which 
the program is meant to address. Each scenario consists of:

1. The threat community (e.g. internal workforce members, nature, partners) 
performing the action.
2. The action taken by the threat actor.
3. The program capabilities that resist harm by the threat and actor.
4. The consequences of the action, should it occur.

With this list of scenarios, ratings are created of the probability of the 
threat acting against the institution, the capabilities of the threat, and 
the size of the loss should the attack overcome the capabilities. A beta pert 
distribution is used to model each of these factors.

## Risk Simulation

We ran a Monte Carlo process of (`r comma(attr(results, "simulation_count"))`) 
simulations of each risk scenario against the control strength for the domain 
assigned to the threat scenario. This process generates the following outputs:

* Threat Events: The number of times per year the threat presents itself
* Loss Events: The number of times the threat results in a loss (the threat 
  overcomes the controls)
* Single Loss Expected (SLE): The size range of individual losses from each 
  loss event
* Annual Loss Expected (ALE): The annualized sum of all individual losses.

## Assumptions

Parameters for each of the input distributions are displayed below.

```{r, table_helper, echo=FALSE}
create_table <- function(label, id) {
  # pandoc.header(label, level = 3)
  filter(mappings, type == id) %>% select(label, l, ml, h, conf) %>% 
    rowwise() %>% 
    mutate(label = stringi::stri_trans_totitle(label)) %>% 
    mutate(l = ifelse(id == "lm", dollar(l), 
                      ifelse(id == "tef", comma(l), percent(l/100)))) %>% 
    mutate(ml = ifelse(id == "lm", dollar(ml), 
                       ifelse(id == "tef", comma(ml), percent(ml/100)))) %>% 
    mutate(h = ifelse(id == "lm", dollar(h), 
                      ifelse(id == "tef", comma(h), percent(h/100)))) %>% 
    rename("Category" = label, "Low"=l, "Most Likely"= ml, "High" = h, 
           "Confidence"=conf) %>% 
    pander::pander(justify = c("left", rep("right", 4)),
               caption = paste(label, "table"))
}
```

### Threat Frequencies

```{r}
create_table("Threat Frequencies", "tef")
```
### Threat Frequencies

```{r}
create_table("Threat Capabilities", "tc")
```

### Control Difficulties

```{r}
create_table("Control Difficulties", "diff")
```

### Loss Magnitudes

```{r}
create_table("Loss Magnitudes", "lm")
```

# Exploratory Analysis

## Loss Frequency

Whether a loss occurs is a function of:

1. Number of times a threat actor acts against the organization
2. The capabilities of the threat actor
3. The difficulty the relevant controls presents to the threat actor

### Loss Frequency by Domain

The following figure shows the density of annualized loss events by domain. Most 
domains are highly right skewed with few annual events leading to loss. 
Exceptions include the FOO, BAR, and BAZ domains.

```{r lef_by_domain, fig.width = 8, fig.height = 8, fig.cap="Loss Frequency by Domain", echo=FALSE}
results %>% group_by(domain_id, simulation) %>%
  summarise(loss_events = sum(loss_events)) %>% 
  ggplot(., aes(x = loss_events)) -> gg
gg <- gg + facet_grid(domain_id ~ ., scales = "free_y", switch = "y")
#gg <- gg + scale_fill_viridis(discrete = TRUE)
gg <- gg + geom_density(alpha = 1/3, fill = viridis(1))
gg <- gg + labs(x = "Loss Events Per Year", 
                title = "Number of Loss Events by Domain")
gg <- gg + theme_minimal()
gg <- gg + theme(strip.text.y = element_text(angle= 180))
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + theme(axis.ticks.y = element_blank(),
                 axis.text.y = element_blank())
print(gg)
```

### Loss Frequency Per Scenario

Looking at the loss events for each individual scenario helps identify 
particular scenarios within each domain worth closer scrutiny. FOO 24 and 
BAZ 38 have a larger than average number of losses.

Note that larger than average loss events does not necessarily imply high risk, 
as the total size of all losses may be small. The size of losses is 
explored in the loss magnitude section.

```{r lef_by_scenario, fig.width = 8, fig.height = 8, fig.cap="Loss Frequency by Scenario", echo=FALSE}
plot_scenarios_by_domain <- function(x) {
  gg <- ggplot(x, aes(x = loss_events, fill = domain_id))
  gg <- gg + facet_wrap(~domain_id + scenario_id,
                        scales = "free_y", strip.position = "bottom")
  gg <- gg + scale_fill_viridis(discrete = TRUE)
  gg <- gg + geom_density(alpha = 1/2)
  #gg <- gg + scale_y_log10(label = dollar)
  gg <- gg + theme_minimal()
  gg <- gg + theme(panel.grid.major = element_blank())
  gg <- gg + theme(panel.grid.minor = element_blank())
  gg <- gg + labs(x = "Loss Frequency",
                  title = "Number of Annual Loss Events by Scenario")
  gg <- gg + theme(legend.position = "none")
  gg <- gg + theme(axis.ticks.y = element_blank(),
                   axis.text.x = element_blank(),
                   axis.text.y = element_blank(),
                   strip.text.y = element_blank())
  print(gg)
}

dat <- results %>% mutate(scenario_id = factor(as.character(scenario_id), 
                                        levels = scenario_order$scenario_id)) %>%
  arrange(domain_id, scenario_id)

plot_scenarios_by_domain(dat)

#sapply(unique(results$domain_id), function(x) { 
#  plot_scenarios_by_domain(r2[r2$domain_id == x, ]) })
```

## Loss Magnitudes

Loss Magnitudes represent the economic impact when a loss materializes. Types of 
losses include fines, response costs (notification & ID theft monitoring), 
increased audit scrutiny, restoration costs, etc. While these types can all be 
individually modeled, this analysis performs an aggregate modelling with an 
absolute upper bound represented as the largest known HIPAA fine of 4.8M USD. 

### ALE Ranges per Scenario

This figure shows the range of expected annual losses (ALE) for each scenario. 

```{r ale_range_by_scenario, fig.height = 8, fig.width=8, fig.cap="Annual Loss Range by Scenario", echo=FALSE}
gg <- results %>% filter(!scenario_id %in% scenario_outliers) %>% 
  ggplot(., aes(x = as.character(scenario_id), 
                          y = ale + 1))
gg <- gg + facet_wrap(~domain_id, scales = "free_x", strip.position = "bottom")
gg <- gg + stat_boxplot(geom = 'errorbar', width = 0.5)
gg <- gg + geom_boxplot(fill = viridis(1), alpha = 1/5, 
                        outlier.color = alpha("black", 1/2), 
                        outlier.shape = NA)
gg <- gg + theme_minimal()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + scale_y_continuous(labels = function(x) { 
  paste0("$", x / 10 ^ 6, "M")})
#gg <- gg + scale_y_continuous(label = dollar)
gg <- gg + labs(x = "Scenario ID", y = "ALE",
                tile = "Loss Ranges by Domain and Scenario")
print(gg)
```

## Risk

Risk is the annualized expected loss across all the scenarios in a domain. 
Within a single domain, risk is capped at the maximum loss scenario within 
that domain. This is a limitation of the interactions between scenarios and 
domains not being defined.

### Risk by Domains

This figure (a violin plot) shows the range of expected annual losses by 
domain. The wider portion of each column represents where the losses are more 
likely to occur. For example, the FOO domain has expected losses not to exceed 
BAR, with simulations extending down to zero (no loss).

```{r risk_by_domain, echo=FALSE, fig.cap="Risk by Domain"}

first_domain <- domain_summary[[1, "domain_id"]]

# plot of all ales
gg <- ggplot(domain_summary, aes(x = domain_id, y = ale + 1))
gg <- gg + geom_hline(aes(yintercept = risk_tolerance["high"]), color = "red") +
  annotate("text", x = first_domain, y = risk_tolerance["high"], 
           label = "High", vjust = -1, hjust = 0)
gg <- gg + geom_hline(aes(yintercept = risk_tolerance["medium"]), 
                      color = "lightsteelblue") +
  annotate("text", x = first_domain, y = risk_tolerance["medium"], 
           label = "Medium", vjust = -1, hjust = 0)
gg <- gg + stat_boxplot(geom = 'errorbar', width = 0.5)
gg <- gg + geom_boxplot(fill = viridis(1), alpha = 1/3,
                        outlier.color = alpha("black", 1/2),
                        outlier.shape = NA)
gg <- gg + geom_boxplot(aes(fill = domain_id), alpha = 1/5, outlier.shape = NA)
# gg <- gg + geom_violin(fill = viridis(1), alpha = 1/5)
gg <- gg + theme_minimal()
gg <- gg + theme(legend.position = "none")
gg <- gg + scale_y_continuous(label = dollar)
gg <- gg + labs(x = "Domain", y = "Annual Expected Loss",
                title = "Range of Annual Losses By Domain")
print(gg)
```

There are `r numbers[length(scenario_outliers)]` domains 
(`r paste(unique(scenario_summary[scenario_summary$scenario_id %in% scenario_outliers, ]$domain_id), collapse=" and ")`) 
with annual loss ranges which far exceed the other scenarios. The domains that 
contain these scenarios are plotted separately to identify the outlying scenarios.

```{r risk_for_outlier_domains, eval = TRUE, echo=FALSE, fig.cap="Risk for Outliers"}
# box plot for the outlier domains
outlier_domains <- scenario_summary %>% 
  filter(scenario_id %in% scenario_outliers) %>% group_by(domain_id) %>% 
  summarise() %>% ungroup()
gg <- results %>% filter(domain_id %in% outlier_domains$domain_id) %>% 
  ggplot(., aes(x = as.character(scenario_id), y = ale))
gg <- gg + facet_grid(. ~ domain_id, scales = "free_x", switch = "x")
gg <- gg + stat_boxplot(geom = 'errorbar', width = 0.5)
gg <- gg + geom_boxplot(aes(fill = domain_id), alpha = 1/5)
#gg <- gg + geom_boxplot(aes(fill = domain_id), alpha = 1/5, outlier.shape = NA)
gg <- gg + scale_fill_viridis(discrete = TRUE)
gg <- gg + theme_minimal()
gg <- gg + scale_y_continuous(label = dollar)
gg <- gg + labs(x = "Scenario ID", y = "Annual Exepected Loss", 
                title = "Domains with Outlier Scenarios")
gg <- gg + theme(panel.background = element_rect(fill = NA, color = "black"))
gg <- gg + theme(legend.position = "none")
print(gg)
```

### Filter Out the Outlying Scenarios

Repeating the above plot across all the scenarios with the outliers removed 
allows examination of the remaining scenarios without distortion. 

```{r annual_loss_no_outliers, fig.cap="Annual Loss Excluding Outliers"}
#scenario_order$scenario_id
gg <- results %>% filter(!scenario_id %in% scenario_outliers) %>% 
  mutate(scenario_id = factor(as.character(scenario_id), 
                              levels = as.character(scenario_order$scenario_id))) %>% 
  arrange(domain_id, scenario_id) %>% ggplot(., aes(x = scenario_id, y = ale))
gg <- gg + facet_grid(~domain_id, scales = "free_x", switch = "x")
gg <- gg + scale_y_continuous(label = dollar)
gg <- gg + labs(x = NULL, y = "Annual Loss", 
                title = "Loss Range for Each Scenario by Domain")
gg <- gg + stat_boxplot(geom = 'errorbar', width = 0.5)
gg <- gg + geom_boxplot(fill = viridis(1), alpha = 1/5, 
                        outlier.color = alpha("black", 1/2), outlier.shape = NA)
gg <- gg + theme_minimal()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + theme(axis.text.x = element_blank())
print(gg)
```

## Miscellanious

### Fragile Scenarios

Fragile scenarios are scenarios where a single control protects against loss. 
While the single control may be effective against the threat community, these 
scenarios should be reviewed to see if additional controls are warranted.

```{r fragile_scenarios}
scenarios %>% rowwise %>% 
  mutate(n_controls = length(stringi::stri_split_fixed(controls, ", ")[[1]])) %>%
  filter(n_controls == 1) %>% 
  arrange(domain_id, scenario_id) %>% 
  select(Domain = domain_id, ID = scenario_id, Scenario = scenario) %>% 
  pander::pander(justify = c("left", "left", "left"), 
                 split.cells = c("10%", "10%", "80%"), 
                 caption="Fragile Scenarios")
```

### Median vs Max ALE

```{r median_vs_max_ale, echo = FALSE, fig.cap="Median vs Maximum Annual Loss"}

# scatter plot of median vs. max ALEs
gg <- ggplot(scenario_summary, aes(x = ale_median, y = ale_max))
gg <- gg + geom_point(position = "jitter", alpha = 1/5, aes(size = loss_events))
#gg <- gg + stat_bin2d(bins = 50) + scale_fill_gradient(low = 'lightblue', high = 'red')
#gg <- gg + stat_binhex(bins = 50) + scale_fill_viridis()
#gg <- gg + geom_text(aes(label = title), size = 4)
gg <- gg + scale_x_log10(labels = dollar) + scale_y_log10(labels = dollar)
gg <- gg + theme_minimal() 
gg <- gg + scale_size_continuous(labels = comma)
gg <- gg + labs(x = "Median ALE", y = "Maxmium ALE", size = "Loss Event Count")
gg <- gg + ggtitle("Median vs Maximum Annual Loss")
print(gg)
```

### Histogram of median ALEs

```{r median_ale_histogram, echo = FALSE, fig.cap="Median Losses"}
# prepare data an init graph
scenario_summary %>% filter(!scenario_id %in% scenario_outliers) %>% 
  ggplot(., aes(x = ale_median)) -> gg

# graph options
gg <- gg + geom_histogram(binwidth = max(gg$data$ale_median) / 50, 
                          aes(y = ..density..),
                          color = "black", fill = "white")
gg <- gg + geom_density(fill = viridis(1), alpha = 1/5)
gg <- gg + scale_x_continuous(labels = dollar) +
  scale_y_continuous(labels = comma)
gg <- gg + theme_minimal()
gg <- gg + labs(x = "Median Annualized Loss", y = element_blank(), 
                title = "Median Losses (No Outliers)")
print(gg)
```

### Histogram/Density of All Simulations

```{r density_all, echo = FALSE, fig.cap="Risk Exposure"}
# init graph
gg <- ggplot(results, aes(x = ale))

# graph options
gg <- gg + geom_histogram(boundary = 0, binwidth = max(range(results$ale) / 50), 
                          color = "white", 
                          fill = viridis(1), alpha = 1/5)
gg <- gg + geom_density(fill = "black")
gg <- gg + scale_x_continuous(labels = dollar) 
gg <- gg + scale_y_continuous(labels = comma)
gg <- gg + labs(x = "Risk Exposure", 
                y = element_blank(), 
                title = "Risk Exposure Over All Simulations")
gg <- gg + theme_minimal()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + theme(axis.line.y = element_line(color = "black", size = 0.15))
gg <- gg + theme(axis.line.x = element_line(color = "black", size = 0.15))
gg <- gg + theme(plot.margin = unit(rep(30, 4), "pt"))
#gg <- gg + geom_point(aes(y=cumloss)) + geom_path(aes <- (y=cumloss, group=1))
print(gg)
```

### Minus Outlier Scenarios

```{r histogram_no_outliers, echo = FALSE, fig.cap="Risk Exposure"}
# prepare data and init graph
results %>% filter(!scenario_id %in% scenario_outliers) %>% 
  ggplot(., aes(x = ale)) -> gg

#graph options
gg <- gg + geom_histogram(binwidth =max(gg$data$ale) / 50, 
                          color = "white", 
                          fill = viridis(1), alpha = 1/5)
#gg <- gg + geom_density(fill = "black")
gg <- gg + scale_x_continuous(labels = dollar) 
gg <- gg + scale_y_continuous(labels = comma)
gg <- gg + labs(x = "Risk Exposure", 
                y = element_blank(), 
                title = "Risk Exposure Over All Non-Outlier Simualations")
gg <- gg + theme_minimal()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + theme(axis.line.y = element_line(color = "black", size = 0.15))
gg <- gg + theme(axis.line.x = element_line(color = "black", size = 0.15))
gg <- gg + theme(plot.margin = unit(rep(30, 4), "pt"))
#gg <- gg + geom_point(aes(y=cumloss)) + geom_path(aes <- (y=cumloss, group=1))
print(gg)
```

# Appendix

Full threat listing

```{r threat_list,, echo=FALSE}
left_join(scenarios, scenario_summary, by = c("scenario_id" = "scenario_id",
                                            "domain_id" = "domain_id")) %>% 
  arrange(desc(ale_median), desc(ale_var)) %>% 
  mutate_each(funs(dollar), ale_median, ale_var) %>% 
  select("ID" = domain_id, 
         "Scenario" = scenario, 
         "Median Annual Loss" = ale_median, 
         "95% Value at Risk" = ale_var) %>% 
  pander::pander(justify = c("left", "left", "right", "right"), 
                 caption="Threat List")
  
  
  # knitr::kable(., row.names = NA, 
  #              col.names = c("ID", "Scenario", "Median Annual Loss",
  #                            "95% Value at Risk"), 
  #              align = c("l", "l", "r", "r"))
```