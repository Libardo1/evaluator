---
title: "Strategic Information Security Risk Analysis"
author: "Evaluator toolkit (https://github.com/davidski/evaluator)"
mainfont: BentonSansRE
output:
  html_document:
    css: styles/html-styles.css
    fig_caption: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
  html_notebook:
    code_folding: hide
    css: styles/html-styles.css
  pdf_document:
    fig_caption: yes
    toc: yes
  word_document:
    reference_docx: styles/word-styles-reference.docx
    toc: yes
    toc_depth: '3'
monofont: Inconsolata
subtitle: Evaluator Report Sample
header-includes:
- \usepackage{draftwatermark}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyfoot[C]{Sample - \thepage}
---

```{r setup, include=FALSE}
page_width <- 6  # page width in inches, used for figure scaling
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, cache = FALSE,
                      fig.align = 'center',
                      fig.width = .95 * page_width)

# try to use pacman to install/load packages, if available
if ("pacman" %in% installed.packages()) {
  pacman::p_load(ggplot2, scales, viridis, dplyr, purrr)
  pacman::p_load(magrittr, extrafont)
  pacman::p_load(psych, readr, tidyr, pander)
} else  {
  library(ggplot2)
  library(extrafont)
  library(scales)
  library(viridis)
  library(dplyr)
  library(purrr)
  library(magrittr)
  library(readr)
  library(psych)
  library(tidyr)
  library(pander)
}

panderOptions('table.split.table', Inf) # allow pander to make pages wide
panderOptions('table.alignment.default', function(df)
    ifelse(sapply(df, is.numeric), 'right', 'left'))
panderOptions('big.mark', ",")
```

```{r load_data, echo = FALSE, message = FALSE}
# Simulations and pre-computed summary views are created via the 
# `strat_risk.Rmd` notebook.
results <- readRDS(file = "./data/simulation_results.Rds") # full results
scenario_summary <- readRDS(file = "./data/scenario_summary.Rds")  # scenario level summary
domain_summary <- readRDS(file = "./data/domain_summary.Rds")    # domain level summary

# details on our scenarios
domains <- read_csv("./data/domains.csv") # domain catalog
mappings <- read_csv("./data/qualitative_mappings.csv") # qualitative translations
capabilities <- read_csv("data/capabilities.csv") # i.e. objectives & controls
risk_tolerances <- read_csv("data/risk_tolerances.csv") # i.e. risk tolerances
scenarios <- read_csv("./data/scenarios.csv") %>% mutate(tef = tolower(tef), 
                                                         lm = tolower(lm), 
                                                         tc = tolower(tc))
```

```{r useful_values}
# assign risk tolerance dataframe as vector
risk_tolerance <- risk_tolerances$amount
names(risk_tolerance) <- risk_tolerances$level %>% tolower
# Precalculate the standard order of scenarios (domain, then ID of the scenario)
scenario_order <- results %>% group_by(domain_id, scenario_id) %>% summarise()
focus_scenarios <- c(51, 11)    # scenarios of particular management interest 
# text vector of numbers to English words
numbers <- c("one", "two", "three", "four", "five", "six", "seven", "eight", 
             "nine")
```

```{r enhance_summary_object}
# assign loss tolerance to median_ale size
scenario_summary %<>% 
  mutate(annual_tolerance = ifelse(ale_median >= risk_tolerance["high"], 
                                   "High", 
                                   ifelse(ale_median >= risk_tolerance["medium"], "Medium", "Low"))) %>% 
  mutate(annual_tolerance = factor(annual_tolerance, 
                                   levels = c("High", "Medium", "Low"), 
                                   ordered = TRUE)) 
# assign outlier as 2 SD larger 95% VAR ALE
scenario_summary %<>% mutate(ale_var_zscore = scale(ale_var), 
                             outlier = ale_var_zscore >= 2)
scenario_outliers <- scenario_summary[which(scenario_summary$outlier == TRUE), 
                                      "scenario_id"] %>% unlist %>% unname
```

```{r helper_functions}
# format dollar amounts in terms of millions of USD
dollar_millions <- function(x) paste0("$", x / 10 ^ 6, "M")

#default theme
theme_evaluator <- function(base_family="BentonSansRE") {
  theme_minimal(base_family = base_family) %+replace% 
    theme(
      panel.border = element_blank(),
      legend.position = "bottom"
    )
}
```

# Summary

> This report is based upon `r comma(attr(results, "simulation_count"))` 
simulations performed over `r comma(length(unique(results$scenario_id)))` 
risk scenarios on `r format(attr(results, "generated_on"), "%F %H:%M:%S%z")`.

Portions of this analysis exclude outlier scenarios. Graphs and tables 
where this occurs are clearly noted.

## Total Simulated Loss Exposure

```{r risk_tolerance_exceedance}
loss_exceedance <- results %>% 
  group_by(simulation) %>% 
  summarize(loss = sum(ale)) %>% 
  mutate(tolerance = ifelse(loss >= risk_tolerance["high"], "High", 
                            ifelse(loss >= risk_tolerance["medium"], "Medium", "Low"))) %>% 
  count(tolerance)
```

Total potential losses for a given year are estimated to exceed the 
institution's major risk threshold of `r dollar(risk_tolerance["high"])` 
`r percent(loss_exceedance[loss_exceedance$tolerance == "High", ]$n/max(results$simulation))` 
of the time.

Interactions between risk scenarios, including an organization's response to a 
major event, should one occur, are not modeled. The following table shows the 
maximum, 95% percentile, mean, 10th percentile, and minimum single year losses.

```{r overall_exposure, echo=FALSE}
overall <- results %>% group_by(simulation) %>% 
                     summarize(ale = sum(ale)) %>% select(ale) %>%
                     ungroup
data_frame("Maximum" = dollar(max(overall$ale)),
           "95th Percentile" = dollar(quantile(overall$ale, c(0.95))),
           "Mean" = dollar(mean(overall$ale)),
           "10th Percentile" = dollar(quantile(overall$ale, c(0.10))),
           "Minimum" = dollar(min(overall$ale))
           ) %>% t %>% pander(justify = "right", 
                              emphasize.rownames = FALSE,
                              caption = paste("Annual Loss", 
                                              "Exposures Across all",
                                              "Simulations"))
```

```{r calculate_max_losses}
max_loss <- results %>% filter(!scenario_id %in% scenario_outliers) %>%  
  group_by(simulation) %>% 
  summarise(loss = max(ale),
            min_loss = min(ale),
            max_loss = sum(ale),
            outliers = FALSE) %>%
  ungroup
max_loss_w_outliers <- results %>% 
  group_by(simulation) %>% 
  summarise(loss = max(ale),
            min_loss = min(ale),
            max_loss = sum(ale),
            outliers = TRUE) %>%
  ungroup
max_loss <- union(max_loss, max_loss_w_outliers)
```

The following figure shows the frequency total losses will exceed a given 
threshold during a given year, both with and without including the outliers. 
The 80% line shows that a loss of no less than 
`r dollar(quantile(filter(max_loss, outliers==FALSE)$loss, .2))` 
occurs every four out of five years. This likely minimum loss with the 
outliers included is `r dollar(quantile(filter(max_loss, outliers==TRUE)$loss, .2))`.

```{r loss_exceedance_curve, fig.cap="Loss Exceedance Curve"}
max_loss %>% 
  group_by(outliers) %>% 
  by_slice(~ arrange(.x, loss) %>% 
             mutate(prob = 1 - percent_rank(loss)), .collate = "rows") %>% 
  ggplot(., aes(prob, loss, color = outliers)) + 
  geom_path() -> gg
gg <- gg + geom_vline(xintercept = 0.8, color = "red", size = 1.1) + 
  annotate("text", x = 0.8, y = max(max_loss$loss), label = percent(.8),
           hjust = 1, size = 3)
gg <- gg + scale_y_continuous(labels = dollar_millions)
gg <- gg + scale_color_viridis(discrete = TRUE, 
                               labels = c("Excluded", "Included"))
gg <- gg + guides(color = guide_legend(title = "Outliers", 
                                       override.aes = list(size = 5)))
gg <- gg + scale_x_reverse(labels = percent)
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + theme(panel.grid.major.x = element_blank())
gg <- gg + labs(x = "Chance of Equal or Greater Loss", y = "Loss", 
                title = "Loss Exceedance Curve",
                subtitle = "Excluding Outlier Scenarios",
                caption = "Source: Evaluator toolkit")
gg
```

## Largest Loss Domains

```{r calculate_domain_impact}
domain_impact <- domain_summary %>%
  group_by(domain_id) %>%
  select(domain_id, ale) %>%
  summarize_each(funs(min, mean, max, sd)) %>%
  arrange(desc(mean)) %>% 
  ungroup %>% 
  left_join(domains, by = c("domain_id" = "domain_id")) %>% 
  mutate(domain = paste0(domain, " (", domain_id, ")"))
```

The top three domains by loss size are `r domain_impact[[1, "domain"]]`, 
 `r domain_impact[[2, "domain"]]`, and `r domain_impact[[3, "domain"]]`.

```{r domain_impact, echo = FALSE}
mutate_each(domain_impact, funs(dollar), -domain_id, -domain) %>% 
  select("Domain" = domain, "Minimum" = min,
         "Mean (Average)" = mean, "Maximum" = max, 
         "Standard Deviation" = sd) %>% 
  pander(justify = c(rep("left", 1), rep("right", 4)),
                 split.cells = 20,
                 caption = "Annual Loss by Domain")
```

## Key Capability Weaknesses

```{r calculate_weak_domains}
# Can't calc mean of means this way!
# control_weakness <- scenario_summary %>% group_by(domain_id) %>% 
#   summarize(vuln = round(mean(mean_vuln), 2)) %>% 
#   arrange(desc(vuln)) %>% 
#   mutate(vuln = percent(vuln)) %>% 
#   ungroup()

control_weakness <- results %>% group_by(domain_id) %>% 
  summarize(loss_events = sum(loss_events), 
            threat_events = sum(threat_events)) %>% 
  mutate(vuln = loss_events / threat_events) %>% 
  arrange(desc(vuln)) %>% 
  mutate(vuln = percent(vuln))
# recalc domain_level tc_exceedance
tc_exceedance <- results %>% group_by(domain_id) %>% 
  mutate(avoided_events = threat_events - loss_events) %>% 
  summarize(tc_exceedance = sum(mean_tc_exceedance * loss_events), 
            diff_exceedance = sum(mean_diff_exceedance * avoided_events),
            avoided_events = sum(avoided_events),
            loss_events = sum(loss_events)) %>% 
  mutate(tc_exceedance = tc_exceedance / loss_events,
         diff_exceedance = diff_exceedance / avoided_events ) %>% 
  mutate(tc_exceedance = ifelse(is.na(tc_exceedance), NA, 
                                percent(tc_exceedance / 100 )),
         diff_exceedance = ifelse(is.na(diff_exceedance), NA, 
                                  percent(diff_exceedance / 100))) %>% 
  select(tc_exceedance, diff_exceedance, domain_id)
left_join(control_weakness, tc_exceedance, by = c("domain_id" = "domain_id")) %>% 
  left_join(domains, by = c("domain_id" = "domain_id")) %>% 
  mutate(domain = paste0(domain, " (", domain_id, ")")) -> control_weakness
```

Threats most frequently overcome the control capabilities, resulting in 
losses, in  the domains of `r control_weakness[[1, "domain"]]`, 
`r control_weakness[[2, "domain"]]`, and `r control_weakness[[3, "domain"]]`.

```{r domain_weakness, echo = FALSE}
select(control_weakness, domain, vuln, tc_exceedance, diff_exceedance) %>% 
  rename("Domain" = domain, 
       "Succesful Threat Events" = vuln,
       "Control Gap" = tc_exceedance,
       "Surplus Control Strength" = diff_exceedance) %>% 
  pander(justify = c("left", "right", "right", "right"), 
                 caption = "Domain Weaknesses")
```
```{r events_contained_vs_losses}
dat <- control_weakness %>% 
  arrange(desc(loss_events), desc(threat_events)) %>% 
  mutate(domain_id = factor(domain_id, levels = rev(unique(domain_id)),
                            ordered = TRUE)) %>% 
  mutate(contained_events = threat_events - loss_events)

# nudge labels 5% off from the end of the segment
label_nudge = c(max(dat$loss_events) / 20 * -1, max(dat$contained_events) / 20)

# set breakpoints to half of the range
break_locations = c(max(dat$loss_events) / 2 * -1, max(dat$contained_events) / 2)

# convert data into tidy-er format
dat <- dat %>% gather(type, events, c(loss_events, contained_events)) %>% 
  mutate(actual_events = events) %>% 
  mutate(events = events + 25000, events = ifelse(type == "loss_events", -1 * events, events)) %>% 
  mutate(nudge = ifelse(type == "loss_events", label_nudge[1], label_nudge[2])) %>% 
  mutate(hjust = ifelse(type == "loss_events", "right", "left")) %>% 
  mutate(full_lab = ifelse(type == "loss_events",
                           sprintf("%s (%s)", comma(actual_events), tc_exceedance),
                           sprintf("%s (%s)", comma(actual_events), diff_exceedance)))

# auto-calculate the limits of the plot
event_range <- range(dat$events) * c(1.6, 1.3)

# graph
gg <- ggplot(dat, aes(x = events, xend = 0, y = domain_id)) -> gg
gg <- gg + geom_segment(aes(yend = domain_id), color = viridis(1))
gg <- gg + geom_point(color = viridis(1), size = 2)
gg <- gg + geom_text(aes(label = full_lab, x = events + nudge, y = domain_id, 
                         hjust = hjust), family = "Museo Sans Cond 300", size = 3)
gg <- gg + geom_label(aes(x = 0, y = domain_id, label = domain_id), size = 3, 
                      label.size = NA)
gg <- gg + scale_x_continuous(expand = c(0,0), breaks = c(break_locations[1], 0, break_locations[2]), 
                              labels = c("← Loss Events", "Domain", "Contained Events →"),
                              position = "top",
                              limits = event_range)
gg <- gg + labs(x = NULL, y = NULL, 
                title = "Simulated Events by Domain",
                subtitle = "Losses vs. Contained",
                caption = "Source: Evaluator toolkit")
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid = element_blank())
gg <- gg + theme(axis.text.y = element_blank())
gg <- gg + theme(axis.ticks.x = element_blank())
gg <- gg + theme(axis.ticks.y = element_blank())
gg
```

## Focus Risk Scenarios

> Identify any scenarios of particular interest here. By highlighting 
those scenarios in which your decission makers have expressed 
interest (e.g. ransomware), these scenarios can be analyzed without losing 
sight of the overall risk picture.

```{r make_scenario_table, echo=FALSE}
display_scenario_table <- function(scenario_summary, id) {
  filter(scenario_summary, scenario_id == id) %>% 
  summarise(
    "Vulnerability (% of events resulting in loss)" = percent(mean_vuln),
    "Mean Control Gap" = percent(mean_tc_exceedance / 100),
    "Maximum Annual Loss" = dollar(ale_max),
    "Median Annual Loss" = dollar(ale_median),
    "Maximum Single Loss" = dollar(sle_max),
    "Median Single Loss" = dollar(sle_median)
  ) %>% t %>% pander(justify = c("left", "right"), 
                     emphasize.rownames = FALSE, 
                     caption = paste("Scenario", id, "Overview"))
}
```

### Key Scenario A

Scenario: `r filter(scenarios, scenario_id == focus_scenarios[1]) %>% select(scenario) %>% unlist %>% unname`

```{r scenarioA_details, echo=FALSE}
display_scenario_table(scenario_summary, focus_scenarios[1])
```

### Key Scenario B

Scenario: `r filter(scenarios, scenario_id == focus_scenarios[2]) %>% select(scenario) %>% unlist %>% unname`


```{r scenarioB_details, echo=FALSE}
display_scenario_table(scenario_summary, focus_scenarios[2])
```

# Methodology

The security team strategic risk assessment process is based upon the 
industry standard OpenFAIR methodology. Expert opinion is polled on the threats, 
capabilities, and probable loss magnitudes associated with key risk scenarios. 
This information is used to create a Monte Carlo model, generating a 
a dollar-quantified risk exposure dollars for each tracked risk.

## Domains

The security program is divided into `r nrow(domains)` domains which provides 
a framework for reviewing the security program. These domains are:

```{r domain_table}
select(domains, "Domain ID" = domain_id, "Domain" = domain) %>%
  arrange(Domain) %>% 
  pander(caption = "Domain Listing", justify = "left", split.cells=c("20%", "80%"))
```

## Capabilities

The security team and key subject matter experts formed a consensus opinion on 
the maturity level of the `r nrow(capabilities)` capabilities 
which make up the `r nrow(domains)` security program domains. The 
team assessed each capability against a five-level capability maturity model 
(patterned after the [CMMI](http://cmmiinstitute.com/) model), 
ranging from initial (level 1) through optimizing (level 5).

These capability ratings are used to create a distribution of simulated 
capability effectiveness over the course of a year, ranging from 100% 
(completely effective) to 0% (completely ineffective).

The full capabilities catalog and their associated ratings is included as [Appendix B](#capabilities_list).

## Risk Scenarios

Each domain of the security program has a list of multiple risk scenarios which 
the program is meant to address. These scenarios consists of:

1. The threat community (e.g. internal workforce members, nature, partners) 
performing the action.
2. The action taken by the threat actor.
3. The program capabilities that resist harm by the threat and actor.
4. The consequences of the action, should it occur.

Working against the scenario list, qualitative ratings are assigned for the 
frequency of the threat acting against the institution, the capabilities of 
the threat, and the size of the loss should the attack overcome the 
security program's capabilities.

```{r scenario_table}
arrange(scenarios, domain_id, scenario_id) %>% 
  mutate(scenario_id = paste(domain_id, scenario_id, sep = " - "), 
         tef = stringi::stri_trans_totitle(tef),
         lm = stringi::stri_trans_totitle(lm)) %>% 
  select("Scenario ID" = scenario_id, "Scenario" = scenario, "Actor" = tcomm, 
         "Action Frequency" = tef, "Impact" = lm) %>% 
  pander(caption = "All Scenarios", justify = "left", split.cells = 20)
```

## Simulation

Each of the qualitative labels is mapped to a set of paremters describing a 
beta pert distribution. These distributions are used to run `r comma(attr(results, "simulation_count"))` 
simulations of each risk scenario. In a given simulation, each scenario is
modeled for potential losses using:

1. The number of times the threat actor acts against the organization.
2. The capabilities of the threat actor.
3. The difficulty the relevant controls present to the threat actor. For 
    scenarios which have multiple controls applied, difficulty is the 
    arithmatic mean of all the applicable controls.

This process generates several outputs:

* Threat Events: The number of times per year the threat presents itself
* Loss Events: The number of times the threat results in a loss (the threat 
  overcomes the controls)
* Single Loss Expected (SLE): The size range of individual losses from each 
  loss event
* Annual Loss Expected (ALE): The annualized sum of all individual losses.

Risk is the total annual expected losses across all scenarios within a given 
simulation.

## Assumptions

Each of the mappings from qualitative labels to quantitative parameters is 
displayed below.

```{r, table_helper, echo=FALSE}
create_table <- function(label, id) {
  # pandoc.header(label, level = 3)
  filter(mappings, type == id) %>% select(label, l, ml, h, conf) %>% 
    rowwise() %>% 
    mutate(label = stringi::stri_trans_totitle(label)) %>% 
    mutate(l = ifelse(id == "lm", dollar(l), 
                      ifelse(id == "tef", comma(l), percent(l/100)))) %>% 
    mutate(ml = ifelse(id == "lm", dollar(ml), 
                       ifelse(id == "tef", comma(ml), percent(ml/100)))) %>% 
    mutate(h = ifelse(id == "lm", dollar(h), 
                      ifelse(id == "tef", comma(h), percent(h/100)))) %>% 
    rename("Category" = label, "Low" = l, "Most Likely" = ml, "High" = h, 
           "Confidence" = conf) %>% 
    pander(justify = c("left", rep("right", 4)),
           caption = paste(label, "table"))
}
```

### Threat Frequencies

```{r threat_frequencies_table}
create_table("Threat Frequencies", "tef")
```

### Threat Capabilities

```{r threat_capabilities_table}
create_table("Threat Capabilities", "tc")
```

### Control Difficulties

```{r control_difficulties_table}
create_table("Control Difficulties", "diff")
```

### Loss Magnitudes

Loss Magnitudes represent the economic impact when a loss event occurs. Types of 
losses include fines, response costs (notification & ID theft monitoring), 
increased audit scrutiny, restoration costs, etc. Instead of modeling different 
loss types (formally defined as primary and secondary losses), this 
analysis takes an aggregate approach with an absolute upper bound for any 
single loss event at the largest known HIPAA fine of $4.8 million. 

```{r loss_magnitudes_table}
create_table("Loss Magnitudes", "lm")
```

# Results

Taking all of the simulations and grouping them by their frequency and size 
of losses generates four categories for describing all the loss scenarios. 
These buckets are:

- Urgent Events: Scenarios with high frequency of losses as well as high 
magnitude of loss.
- Asteroid Events: Scenarios which occur infrequently yet have high loss 
magnitudes when the do occur.
- Annoyance Events: Scenarios which incure losses often but with low impact.
- Contained Scenarios: Scenarios which occur infrequently (if at all) and which 
have low impact upon the organization when they do occur.

```{r frequency_and_impact_plot}
gg <- ggplot(scenario_summary, aes(x = loss_events_median, y = sle_mean, 
                                   size = ale_median, color = annual_tolerance, 
                                   text = scenario_id))
gg <- gg + geom_point()
gg <- gg + labs(title = "Loss Frequency vs Magnitude",
           subtitle = "All Scenarios",
           x = "Median Events per Year",
           y = "Median Event Magnitude")
gg <- gg + scale_x_continuous(labels = comma)
gg <- gg + scale_y_continuous(labels = dollar_millions)
gg <- gg + scale_color_viridis(discrete = TRUE, drop = FALSE)
gg <- gg + scale_size_continuous(labels = dollar_millions)
gg <- gg + guides(size = guide_legend(title = "Median Annual Loss", 
                                      title.position = "top"))
gg <- gg + guides(color = guide_legend(title = "Total Losses vs Risk Tolerance", 
                                       title.position = "top"))
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid.minor = element_blank())
gg
```

## High Frequency and High Impact

Urgent scenarios which require immediate treatment.

```{r high_frequency_high_impact}
dat <- filter(results, scenario_id %in% c(51, 11, 12))

gg <- ggplot(dat, aes(x = loss_events, y = sle_median, color = ale))
gg <- gg + geom_point(alpha = 1/50)
gg <- gg + labs(title = "Loss Frequency vs Magnitude",
           subtitle = "All Scenarios",
           x = "Median Events per Year",
           y = "Median Event Magnitude")
gg <- gg + scale_x_continuous(labels = comma)
gg <- gg + scale_y_continuous(labels = dollar_millions)
gg <- gg + scale_color_viridis(labels = dollar_millions)
gg <- gg + guides(color = guide_legend(title = "Annual Loss Exposure"))
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid.minor = element_blank())
gg
```


## Low Frequency and High Impact

Asteroid scenarios which 

## High Frequency and Low Impact

Annoyances where improvements can save not just loss impacts, but free up 
operational time from not having to respond to events.

## Low Frequency and Low Impact

Contained scenarios where additional investments are likely unwarranted.

## Loss Frequency

Overall frequency of loss events is displayed at the domain and at the 
scenario level.

### Loss Frequency by Domain

```{r prepare_skewness_and_kurtosis}
domain_loss_frequency <- results %>% slice_rows("domain_id") %>% 
  by_slice(~ describe(.x$loss_events), .collate = "rows") %>% select(-vars)

if (sum(domain_loss_frequency$Skew <= 0, na.rm = TRUE) == 0) {
  narrative <- paste("All domains are positive skewed,",
                     "indicating loss events are clustered to",
                     "the lower ranges.")
}

names(domain_loss_frequency) <- names(domain_loss_frequency) %>% 
  stringi::stri_trans_totitle()
```

```{r display_skew_kurt_table}
pander(domain_loss_frequency, 
       caption = "Loss Events by Domain Summary Statistics") 
```

The following figure shows the density of annualized loss events by domain. `r narrative`

```{r lef_by_domain, fig.cap="Loss Frequency by Domain"}
results %>% group_by(domain_id, simulation) %>%
  summarise(loss_events_median = median(loss_events)) %>% 
  ggplot(., aes(x = loss_events_median)) -> gg
gg <- gg + facet_grid(domain_id ~ ., scales = "free_y", switch = "y")
#gg <- gg + scale_fill_viridis(discrete = TRUE)
gg <- gg + geom_density(fill = viridis(1))
gg <- gg + labs(x = "Loss Events Per Year", 
                y = element_blank(),
                title = "Median Loss Events",
                subtitle = "All Scenarios Included",
                caption = "Source: Evaluator toolkit")
gg <- gg + theme_evaluator()
gg <- gg + theme(strip.text.y = element_text(angle = 180))
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + theme(axis.ticks.y = element_blank(),
                 axis.text.y = element_blank())
print(gg)
```

### Loss Frequency by Scenario

Looking at the number of loss events for each scenario helps identify 
scenarios worth closer scrutiny. Scenarios which have larger number of losses 
than typical for the entire simulation are:

```{r loss_events_by_scenario_table}
loss_events_by_scenario <- results %>% group_by(scenario_id) %>% 
   summarize(n = mean(loss_events))
loss_events_by_scenario %>% mutate(n_zscore = scale(n)) %>% 
  filter(n_zscore >= 2) %>% 
  arrange(desc(n)) %>% 
  select("Loss Events" = n, scenario_id) %>% 
  left_join(scenarios, by = c("scenario_id" = "scenario_id")) %>% 
  mutate("Scenario ID" = paste0(domain_id, " - ", scenario_id),
         "Mean Loss Events" = comma(round(`Loss Events`))) %>% 
  select(`Scenario ID`, `Mean Loss Events`) %>% 
  pander(justify = c("left", "right"))
```

Note that larger than average loss events does not necessarily imply high risk, 
as the total size of all losses may be small. The size of losses is 
explored in the loss magnitude section.

```{r lef_by_scenario, fig.cap="Loss Frequency by Scenario"}
plot_scenarios_by_domain <- function(x) {
  gg <- ggplot(x, aes(x = loss_events, fill = domain_id))
  gg <- gg + facet_wrap(~domain_id + scenario_id,
                        scales = "free_y", strip.position = "bottom")
  gg <- gg + scale_fill_viridis(discrete = TRUE)
  gg <- gg + geom_density()
  #gg <- gg + scale_y_log10(label = dollar)
  gg <- gg + labs(x = "Loss Frequency", y = NULL,
                  title = "Distribution of Loss Event Frequencies",
                  caption = "Source: Evaluator toolkit")
  gg <- gg + theme_evaluator()
  gg <- gg + theme(panel.grid.major = element_blank())
  gg <- gg + theme(panel.grid.minor = element_blank())
  gg <- gg + theme(legend.position = "none")
  gg <- gg + theme(axis.ticks.y = element_blank(),
                   axis.text.x = element_blank(),
                   axis.text.y = element_blank(),
                   strip.text.y = element_blank())
  print(gg)
}

dat <- results %>% mutate(scenario_id = factor(as.character(scenario_id), 
                                        levels = scenario_order$scenario_id)) %>%
  arrange(domain_id, scenario_id)

plot_scenarios_by_domain(dat)

#sapply(unique(results$domain_id), function(x) { 
#  plot_scenarios_by_domain(r2[r2$domain_id == x, ]) })
```

## Loss Magnitudes

This figure shows the range of expected annual losses (ALE) for each scenario, 
with **outliers excluded**.

```{r ale_range_by_scenario, fig.cap="Annual Loss Range by Scenario"}
gg <- results %>% filter(!scenario_id %in% scenario_outliers) %>% 
  ggplot(., aes(x = as.character(scenario_id), 
                          y = ale + 1))
gg <- gg + facet_wrap(~domain_id, scales = "free_x", strip.position = "bottom")
gg <- gg + stat_boxplot(geom = 'errorbar', width = 0.5)
gg <- gg + geom_boxplot(fill = viridis(1),
                        outlier.color = viridis(1), outlier.alpha = 1/2, 
                        outlier.shape = 16)
gg <- gg + scale_y_continuous(labels = dollar_millions)
#gg <- gg + scale_y_continuous(label = dollar)
gg <- gg + labs(x = "Scenario ID", y = "Annual Loss Exposure",
                title = "Loss Ranges by Domain and Scenario",
                subtitle = "Outliers excluded",
                caption = "Source: Evaluator toolkit")
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())

print(gg)
```

## Total Risk

### Risk by Domain

This figure shows the range of expected annual losses by domain.

```{r risk_by_domain, fig.cap="Risk by Domain"}

test_position <- domain_summary[[nrow(domain_summary), "domain_id"]]

# plot of all ales
gg <- ggplot(domain_summary, aes(x = domain_id, y = ale + 1))
gg <- gg + geom_hline(aes(yintercept = risk_tolerance["high"]), color = "red") +
  annotate("text", x = test_position, y = risk_tolerance["high"], 
           label = "High", vjust = "bottom", hjust = "right")
gg <- gg + geom_hline(aes(yintercept = risk_tolerance["medium"]), 
                      color = "lightsteelblue") +
  annotate("text", x = test_position, y = risk_tolerance["medium"], 
           label = "Medium", vjust = "bottom", hjust = "right")
gg <- gg + stat_boxplot(geom = 'errorbar', width = 0.5)
gg <- gg + geom_boxplot(fill = viridis(1), alpha = 1/5,
                        outlier.color = "black", outlier.alpha = 1/2,
                        outlier.shape = 16)
#gg <- gg + geom_boxplot(aes(fill = domain_id), alpha = 1/5, outlier.shape = NA)
#gg <- gg + geom_violin(fill = viridis(1), alpha = 1/5)
gg <- gg + scale_y_continuous(labels = dollar_millions)
gg <- gg + labs(x = "Domain", y = "Annual Loss Exposure",
                title = "Range of Annual Losses by Domain",
                subtitle = "Outliers Included",
                caption = "Source: Evaluator toolkit")
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + theme(legend.position = "none")
print(gg)
```

There are `r numbers[length(scenario_outliers)]` domains 
(`r paste(unique(scenario_summary[scenario_summary$scenario_id %in% scenario_outliers, ]$domain_id), collapse=" and ")`) 
with annual loss ranges which far exceed the other scenarios. The domains that 
contain these scenarios are plotted separately to identify the outlying 
scenarios.

```{r risk_for_outlier_domains, fig.cap="Risk for Outliers"}
# box plot for the outlier domains
outlier_domains <- scenario_summary %>% 
  filter(scenario_id %in% scenario_outliers) %>% group_by(domain_id) %>% 
  summarise() %>% ungroup()
test_position <- tail(outlier_domains, n=1) %>% select(domain_id) %>%  unlist %>% unname
gg <- results %>% filter(domain_id %in% outlier_domains$domain_id) %>% 
  ggplot(., aes(x = as.character(scenario_id), y = ale))
gg <- gg + facet_grid(. ~ domain_id, scales = "free_x", switch = "x")
gg <- gg + stat_boxplot(geom = 'errorbar', width = 0.5)
gg <- gg + geom_boxplot(aes(fill = domain_id), alpha = 1/5)
#gg <- gg + geom_boxplot(aes(fill = domain_id), alpha = 1/5, outlier.shape = NA)
gg <- gg + geom_hline(aes(yintercept = risk_tolerance["high"]), color = "red") +
  annotate("text", x = test_position, y = risk_tolerance["high"], 
           label = "High", vjust = "bottom", hjust = "right")
gg <- gg + geom_hline(aes(yintercept = risk_tolerance["medium"]), 
                      color = "lightsteelblue") +
  annotate("text", x = test_position, y = risk_tolerance["medium"], 
           label = "Medium", vjust = "bottom", hjust = "right")
gg <- gg + scale_fill_viridis(discrete = TRUE)
gg <- gg + scale_y_continuous(labels = dollar_millions)
gg <- gg + labs(x = "Domain / Scenario ID", y = "Annual Loss Exposure", 
                title = "Domain with Outlier Scenarios",
                subtitle = "Single scenarios within domains can dwarf other scenarios",
                caption = "Source: Evaluator toolkit")
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.background = element_blank(),
                 panel.grid = element_blank(),
                 panel.border = element_blank())
gg <- gg + theme(legend.position = "none")
print(gg)
```

### Risk by Domain without Outliers

Repeating the above plot across all the scenarios with the outliers removed 
allows examination of the remaining scenarios without distortion. 

```{r annual_loss_no_outliers, fig.cap="Annual Loss Excluding Outliers"}
#scenario_order$scenario_id
gg <- results %>% filter(!scenario_id %in% scenario_outliers) %>% 
  mutate(scenario_id = factor(as.character(scenario_id), 
                              levels = as.character(scenario_order$scenario_id))) %>% 
  arrange(domain_id, scenario_id) %>% ggplot(., aes(x = scenario_id, y = ale))
gg <- gg + facet_grid(~domain_id, scales = "free_x", switch = "x")
gg <- gg + labs(x = NULL, y = "Annual Loss Exposure", 
                title = "Loss Range for Each Scenario by Domain",
                subtitle = "Outliers Excluded",
                caption = "Source: Evaluator toolkit")
gg <- gg + stat_boxplot(geom = 'errorbar', width = 0.5)
gg <- gg + geom_boxplot(fill = viridis(1),
                        outlier.color = "black", outlier.size = 1/5, 
                        outlier.alpha = 1/20, outlier.shape = 16)
gg <- gg + scale_y_continuous(labels = dollar_millions)
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
gg <- gg + theme(axis.text.x = element_blank())
print(gg)
```

### Fragile Scenarios

Fragile scenarios are scenarios where a single control protects against loss. 
While the single control may be effective against the threat community, these 
scenarios should be reviewed to see if additional controls are warranted.

```{r fragile_scenarios}
scenarios %>% left_join(domains, by = c("domain_id" = "domain_id")) %>% 
  rowwise %>% 
  mutate(n_controls = length(stringi::stri_split_fixed(controls, ", ")[[1]])) %>%
  filter(n_controls == 1) %>% 
  arrange(domain_id, scenario_id) %>% 
  mutate("Domain" = paste0(domain, " (", domain_id, ")")) %>% 
  select(Domain, "Scenario ID" = scenario_id, 
         Scenario = scenario) %>% 
  pander(justify = c("left", "left", "left"), 
                 split.cells = c("45%", "5%", "50%"), 
                 caption = "Fragile Scenarios")
```

### Median vs Maximum Annual Loss Exposure

```{r median_vs_max_ale, fig.cap="Median vs Maximum Annual Loss"}

# scatter plot of median vs. max ALEs
gg <- ggplot(scenario_summary, aes(x = ale_median, y = ale_max))
gg <- gg + geom_point(position = "jitter", alpha = 1/5, aes(size = loss_events_median))
#gg <- gg + stat_bin2d(bins = 50) + scale_fill_gradient(low = 'lightblue', high = 'red')
#gg <- gg + stat_binhex(bins = 50) + scale_fill_viridis()
#gg <- gg + geom_text(aes(label = title), size = 4)
gg <- gg + scale_x_continuous(labels = dollar_millions)
#gg <- gg + scale_x_continuous(trans = "log10", labels = dollar, expand = c(000, 5 * 10 ^ 7))
gg <- gg + scale_y_continuous(labels = dollar_millions)
gg <- gg + scale_size_continuous(labels = comma)
gg <- gg + labs(x = "Median ALE", y = "Maxmium ALE", size = "Loss Event Count", 
                title = "Median vs Maximum Annual Loss", 
                subtitle = "Outliers Included",
                caption = "Source: Evaluator toolkit")
gg <- gg + theme_evaluator() 
gg <- gg + theme(panel.grid.minor = element_blank())
print(gg)
```

### Median Annual Losses

```{r median_ale_histogram, echo = FALSE, fig.cap="Median Losses"}
# prepare data an init graph
scenario_summary %>% filter(!scenario_id %in% scenario_outliers) %>% 
  ggplot(., aes(x = ale_median)) -> gg

# graph options
gg <- gg + geom_histogram(binwidth = max(gg$data$ale_median) / 50, 
                          aes(y = ..density..),
                          color = "black", fill = "white")
gg <- gg + geom_density(fill = viridis(1), alpha = 1/5)
gg <- gg + scale_x_continuous(labels = dollar_millions) +
  scale_y_continuous(labels = comma)
gg <- gg + labs(x = "Median Annualized Loss", y = element_blank(), 
                title = "Median Losses",
                subtitle = "Outliers Excluded",
                caption = "Source: Evaluator toolkit")
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
print(gg)
```

### Risk Exposure with Outliers

Histogram of all annual losses, across all scenarios and simulations. Zero 
loss scenarios are **excluded** while outliers are **included**.

```{r density_all, echo = FALSE, fig.cap="Risk Exposure"}
# init graph
results %>% filter(ale != 0) %>% ggplot(., aes(x = ale)) -> gg
binwidth <- max(range(gg$data$ale) / 50)

# graph options
gg <- gg + geom_histogram(boundary = 0, binwidth = binwidth, 
                          color = "white", 
                          fill = viridis(1), alpha = 1/5)
gg <- gg + geom_density(fill = "black", alpha = 1/5, 
                        aes(y = get("binwidth", envir = .GlobalEnv) * ..count..))
gg <- gg + scale_x_continuous(labels = dollar_millions) 
gg <- gg + scale_y_continuous(labels = comma)
gg <- gg + labs(x = "Annual Loss Exposure", 
                y = element_blank(), 
                title = "Risk Exposure",
                subtitle = "Outlier Scenarios Included, Zero Loss Scenarios Excluded",
                caption = "Source: Evaluator toolkit")
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
#gg <- gg + theme(axis.line.y = element_line(color = "black", size = 0.15))
#gg <- gg + theme(axis.line.x = element_line(color = "black", size = 0.15))
#gg <- gg + theme(plot.margin = unit(rep(1, 4), "pt"))
#gg <- gg + geom_point(aes(y=cumloss)) + geom_path(aes <- (y=cumloss, group=1))
print(gg)
```

### Risk Exposure without Outliers

Histogram of all annual losses, across all scenarios and simulations. Zero 
loss scenarios and outliers are **excluded**.

```{r histogram_no_outliers, echo = FALSE, fig.cap="Risk Exposure"}
# prepare data and init graph
results %>% filter(!scenario_id %in% scenario_outliers) %>% 
  filter(ale != 0) %>% 
  ggplot(., aes(x = ale)) -> gg
binwidth <- max(range(gg$data$ale) / 50)

#graph options
gg <- gg + geom_histogram(boundary = 0, binwidth = binwidth, 
                          color = "white", 
                          fill = viridis(1), alpha = 1/5)
gg <- gg + geom_density(fill = "black", alpha = 1/5, 
                        aes(y = get("binwidth", envir = .GlobalEnv) * ..count..))
gg <- gg + scale_x_continuous(labels = dollar_millions) 
gg <- gg + scale_y_continuous(labels = comma)
gg <- gg + labs(x = "Annual Loss Exposure", 
                y = NULL, 
                title = "Risk Exposure",
                subtitle = "Outliers and Zero Loss Scenarios Excluded",
                caption = "Source: Evaluator toolkit")
gg <- gg + theme_evaluator()
gg <- gg + theme(panel.grid.major = element_blank())
gg <- gg + theme(panel.grid.minor = element_blank())
print(gg)
```

# Recommendations

> Recommendations are left for the analyst to complete. Typical types of 
recommendations include security improvement projects (projects that 
increase the strenght of controls) and analysis improvement opportunities 
(projects that increase the quality of the inputs).

## Project Recommendation

> Document the key risk management projects for the coming planning period 
(typically yearly) that are either approved or proposed. These projects 
should address the findings from the simulated scenarios by improving controls, 
reducing loss, or transferring risk. Describe each project in terms of its 
expected cost versus the amount of loss exposure addressed by the control.

- FOO
    + Description - 
    + Cost
    + Expected Risk Reduction
- BAR
    + Description - 
    + Cost
    + Expected Risk Reduction
- BAZ
    + Description - 
    + Cost
    + Expected Risk Reduction
- QUX
    + Description -
    + Cost
    + Expected Risk Reduction
- UIER
    + Description - 
    + Cost
    + Expected Risk Reduction
- CORGE
    + Description - 
    + Cost
    + Expected Risk Reduction
- QUUX
    + Description - 
    + Cost -
    + Expected Risk Reduction

## Analysis Improvement Opportunities

>The objective of a risk analysis is to provide better information and to 
reduce uncertainty in making strategic resource allocation decisions. 
One of the factors in planning should include considering if additional 
information is needed to make better risk analysis. Additional data or 
higher confidence data may reduce the variability in your projections.

Typical areas for additional data include:

- Control Effectiveness Refinement
- Scenario Refinement
- Loss Magnitude Refinement

# Appendicies

## Appendix A {#scenario_list}

```{r risk_list, echo=FALSE}
left_join(scenarios, scenario_summary, by = c("scenario_id" = "scenario_id",
                                            "domain_id" = "domain_id")) %>% 
  arrange(desc(ale_median), desc(ale_var)) %>% 
  mutate_each(funs(dollar), ale_median, ale_var) %>% 
  mutate("Domain" = paste(domain_id, scenario_id, sep = " - ")) %>% 
  select(Domain,
         "Scenario" = scenario, 
         "Median Annual Loss" = ale_median, 
         "95% Value at Risk" = ale_var) %>% 
  pander(split.cells = 20, justify = c("left", "left", "right", "right"), 
                 caption = "Scenario List")
```

## Appendix B {#capabilities_list}

```{r capabilities_table}
arrange(capabilities, domain_id, id) %>%
  select("Domain ID" = domain_id, "Capability" = capability, "Maturity" = diff) %>%
  pander(., caption = "Capability Listing", split.cells = c(10, 40, 10), 
         justify = c('left', 'left', 'left'))

```
