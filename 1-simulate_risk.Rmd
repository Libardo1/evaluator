---
title: "Strategic Information Security Risk Simulation"
author: "Evaluator toolkit (https://github.com/davidski/evaluator)"
output:
  html_document: default
  pdf_document: default
params:
  save_flag: TRUE
  simulation_count: 10000
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r support_setup}
if ("pacman" %in% installed.packages()) {
  pacman::p_load(tidyverse, pbapply, readr, magrittr)
  if (!pacman::p_isinstalled(stringi)) {
    pacman::p_install(stringi)
  }
} else {
  library(tidyverse)
  library(pbapply)
  library(readr)
  library(magrittr)
  library(stringi)
}
source("bin/qual_to_quant.R")  # custom quant/qual conversions
source("bin/openfair.R")       # OpenFAIR simulator
```

If you want to save the simulation run, set the `save_flag` variable to `TRUE`.
Set the number of simualations to run for each scenario in the `simulation_count` 
variable.

```{r parameter_setup}
save_flag <- params$save_flag
simulation_count <- params$simulation_count
```

## Load Source Data

| Source       | Purpose                 |
|--------------|-------------------------|
| Domains      | Program domains         |
| Capabilities | Objectives and controls |
| Scenarios    | Risk scenarios          |
| Mappings     | Distribution params     |


```{r data_load, warning=FALSE}
domains <- read_csv("data/domains.csv") # program domains
capabilities <- read_csv("data/capabilities.csv") # i.e. objectives & controls
scenarios <- read_csv("data/scenarios.csv") %>% 
  mutate_each(funs(tolower), c(tef, lm, tc)) # risk scenarios
mappings <- read_csv("data/qualitative_mappings.csv") # pre-assigned dist.
```

## Apply Quantitative Distributions

Scenarios have qualititative labels applied to them. In this section, we 
convert these quantitative labeles to beta PERT parameters from which we 
will sample during the simulations.

### Difficulty (Control Strength)

With a list of all the relevant controls for each scenario, we can translate 
the qualitative maturity (CMM) score of each control into a distribution 
(H/M/L/Conf). This set of control strength distributions is later used 
to sample an overall difficulty (DIFF) for each scenario.

```{r encode_capabilities}
derive_controls <- function(x, id="None") {
  control_list <- stringi::stri_split_fixed(x, ", ") %>% unlist()
  
  # rather than hard-code the conversions, use the external mappings table
  results <- capabilities[capabilities$id %in% 
                            as.numeric(control_list), "diff"] %>% 
    rename(label=diff) %>% 
    mutate(label=as.character(label)) %>% 
    convert_qual_to_quant(qual_type = "diff")
  
  results <- list(id = results)
  names(results) <- id
  return(results)
}

control_params <- map2(scenarios$controls, scenarios$scenario_id, 
                       ~derive_controls(.x, .y)) %>%
  flatten
names(control_params) <- scenarios$scenario_id
```

### Threats Encoding

Convert the various qualitative labels for the threat and loss information to 
the assigned quantitative distribution parameters (H/M/L/Conf). Each single 
qualitative parameter is converted into four parameters prefixed with the 
relevant OpenFAIR element. For example, the threat expected frequency (TEF) 
generates the parameters:

- `tef_l` - Lower bound of frequency
- `tef_ml` - Most Likely frequency
- `tef_h` - Upper bound of frequency
- `tef_conf` - Confidence of frequency estimates

```{r encode_threats}
# fetch TEF params
scenarios %>% left_join(mappings[mappings$type == "tef",], 
                        by = c("tef" = "label")) %>%
  rename(tef_l = l, 
         tef_ml = ml, 
         tef_h = h, 
         tef_conf = conf) %>% 
  select(-c(tef, type)) -> scenarios

# fetch TC params
scenarios %>% left_join(mappings[mappings$type == "tc",], 
                        by = c("tc" = "label")) %>%
  rename(tc_l = l, 
         tc_ml = ml, 
         tc_h = h, 
         tc_conf = conf) %>% 
  select(-c(tc, type)) -> scenarios

# fetch LM params
scenarios %>% left_join(mappings[mappings$type == "lm",], 
                        by = c("lm" = "label")) %>%
  rename(lm_l = l, 
         lm_ml = ml, 
         lm_h = h, 
         lm_conf = conf) %>% 
  select(-c(lm, type)) -> scenarios
```

## Run Simulations

Run the simulations. We perform `r prettyNum(simulation_count, big.mark=",")`
simulations per threat scenario. After some light munging, a `results` object 
is returned with metadata (attributes on the object) to note the date when these 
simulations were peformed.

```{r run_simulations}
# the use of the list and the pblapply vs pbapply is a hack
# for some reason, pbapply over rows wasn't giving x as a dataframe
scen_list <- split(scenarios, seq(nrow(scenarios)))
results <- pblapply(scen_list, function(x) {
    calculate_ale(scenario = x,
                  diff_estimates = control_params[[as.character(x$scenario_id)]],
                  n = simulation_count,
                  title = x$scenario_id,
                  verbose = FALSE)
})
rm(scen_list)

results <- bind_rows(results)

# convert title back to scenario_id
results <- results %>% mutate(title = as.integer(title)) %>% 
  rename(scenario_id = title)

# add the domain_id column
scenarios2 <- scenarios %>% select(scenario_id, domain_id)
results <- results %>% left_join(scenarios2, 
                                 by = c("scenario_id" = "scenario_id"))
rm(scenarios2)

# calculate the vuln percentage
# note that for no threat events, we report a NA vuln value
results <- results %>% mutate(vuln = 1 - (threat_events - loss_events) /
                                threat_events, 
                              vuln = ifelse(vuln < 0, 0, vuln))

# store the date on which this simulation set was generated
attr(results, "generated_on") <- Sys.time()
# store how many simulations ran on each scenario
attr(results, "simulation_count") <- simulation_count

```

## Create summary views

Calculate summary statistics for each scenario, reducing all the individual 
simulations to descriptors.

```{r summarize_scenarios}
scenario_summary <- results %>% group_by(domain_id, scenario_id) %>% 
  summarise(
    loss_events_mean = mean(loss_events, na.rm = TRUE),
    loss_events_min = min(loss_events, na.rm = TRUE),
    loss_events_max = max(loss_events, na.rm = TRUE),
    loss_events_median = median(loss_events, na.rm = TRUE),
    ale_median = median(ale, na.rm = TRUE),
    ale_max = max(ale, na.rm = TRUE),
    ale_var = quantile(ale, 0.95),
    sle_mean = mean(sle_median, na.rm = TRUE),
    sle_median = median(sle_median, na.rm = TRUE),
    sle_max = max(sle_max, na.rm = TRUE),
    sle_min = min(sle_min, na.rm = TRUE),
    mean_tc_exceedance = sum(mean_tc_exceedance * loss_events) / sum(loss_events),
    mean_diff_exceedance = sum(mean_diff_exceedance * 
                                 (threat_events - loss_events)) / 
      sum(threat_events - loss_events),
    mean_vuln = mean(vuln, na.rm = TRUE)) %>%
  mutate(sle_median = ifelse(is.nan(sle_median), NA, sle_median)) %>%
  ungroup()

# calculate z-score for ALE VaR and assign outliers as >= 2 SD
scenario_summary %<>% mutate(ale_var_zscore = scale(ale_var), 
                             outlier = ale_var_zscore >= 2)
scenario_summary
```

Also aggregate all the scenarios in each domain to the total losses experienced 
in a single simulation, giving the total annual expected loss (ALE per 
domain + simulation).

```{r summarize_by_domain}
domain_summary <- results %>% group_by(domain_id, simulation) %>% 
  summarise(ale = sum(ale)) %>%
  left_join(domains, by = c("domain_id" = "domain_id"))
domain_summary
```

Save the detailed results (`results`), per-scenario summaries 
(`scenario_summary`), domain summaries (`domain_summary`), and the 
full scenarios with parameters (`scenarios_full`).

```{r save_data, eval=save_flag}
saveRDS(scenarios, file = "./data/scenarios_full.Rds")
saveRDS(results, file = "./data/simulation_results.Rds")
saveRDS(scenario_summary, file = "./data/scenario_summary.Rds")
saveRDS(domain_summary, file = "./data/domain_summary.Rds")
file.info(c("data/simulation_results.Rds", "data/scenario_summary.Rds", 
            "data/domain_summary.Rds", "data/scenarios_full.Rds"))
```