---
title: "Strategic Information Security Risk Simulation"
author: "Evaluator toolkit (https://github.com/davidski/evaluator)"
params:
  write_files:
    label: "Write results to disk"
    value: TRUE
    choices: [TRUE, FALSE]
  simulation_count: 
    label: "Number of simulations to run on each scenarios"
    value: 10000
    min: 1
    max: !r 1 * 10^5
output:
  html_document: default
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r support_setup}
if ("pacman" %in% installed.packages()) {
  pacman::p_load(tidyverse, tcltk, readr, magrittr)
  if (!pacman::p_isinstalled(stringi)) {
    pacman::p_install(stringi)
  }
} else {
  library(tidyverse)
  library(tcltk)
  library(readr)
  library(magrittr)
  library(stringi)
}
source("bin/qual_to_quant.R")  # custom quant/qual conversions
source("bin/openfair.R")       # OpenFAIR simulator
```

If you want to save the simulation run, set the `write_files` variable to `TRUE`.
Set the number of simualations to run for each scenario in the `simulation_count` 
variable.

```{r parameter_setup}
save_flag <- params$write_files
simulation_count <- params$simulation_count
```

## Load Source Data

| Source       | Purpose                 |
|--------------|-------------------------|
| Domains      | Program domains         |
| Capabilities | Objectives and controls |
| Scenarios    | Risk scenarios          |
| Mappings     | Distribution params     |


```{r data_load, warning=FALSE}
domains <- read_csv("data/domains.csv") # program domains
capabilities <- read_csv("data/capabilities.csv") # i.e. objectives & controls
scenarios <- read_csv("data/scenarios.csv") %>% 
  mutate_each(funs(tolower), c(tef, lm, tc)) # risk scenarios
mappings <- read_csv("data/qualitative_mappings.csv") # pre-assigned dist.
```

## Apply Quantitative Distributions

Scenarios have qualititative labels applied to them. In this section, we 
convert these quantitative labeles to beta PERT parameters from which we 
will sample during the simulations.

### Difficulty (Control Strength)

With a list of all the relevant controls for each scenario, we can translate 
the qualitative maturity (CMM) score of each control into a distribution 
(H/M/L/Conf). This set of control strength distributions is later used 
to sample an overall difficulty (DIFF) for each scenario.

```{r encode_capabilities}
derive_controls <- function(x, id="None") {
  control_list <- stringi::stri_split_fixed(x, ", ") %>% unlist()
  
  # rather than hard-code the conversions, use the external mappings table
  results <- capabilities[capabilities$id %in% 
                            as.numeric(control_list), "diff"] %>% 
    rename(label=diff) %>% 
    mutate(label=as.character(label)) %>% 
    convert_qual_to_quant(qual_type = "diff")
  
  results <- list(id = results)
  names(results) <- id
  return(results)
}

control_params <- map2(scenarios$controls, scenarios$scenario_id, 
                       ~derive_controls(.x, .y)) %>%
  flatten
names(control_params) <- scenarios$scenario_id

# verify that we were able to encode everything
unencoded_params <- control_params %>% map(~ sum(!complete.cases(.))) %>% 
  unlist(use.names=FALSE) %>% sum
if (unencoded_params > 0) {
  stop("Not able to translate all capabilities to parameters. ", 
       "Does qualitative_mappings.csv match what the values in the spreadsheet?")
}
```

### Threats Encoding

Convert the various qualitative labels for the threat and loss information to 
the assigned quantitative distribution parameters (H/M/L/Conf). Each single 
qualitative parameter is converted into four parameters prefixed with the 
relevant OpenFAIR element. For example, the threat expected frequency (TEF) 
generates the parameters:

- `tef_l` - Lower bound of frequency
- `tef_ml` - Most Likely frequency
- `tef_h` - Upper bound of frequency
- `tef_conf` - Confidence of frequency estimates

```{r encode_threats}
# fetch TEF params
scenarios %>% left_join(mappings[mappings$type == "tef",], 
                        by = c("tef" = "label")) %>%
  rename(tef_l = l, 
         tef_ml = ml, 
         tef_h = h, 
         tef_conf = conf) %>% 
  select(-c(tef, type)) -> scenarios

# fetch TC params
scenarios %>% left_join(mappings[mappings$type == "tc",], 
                        by = c("tc" = "label")) %>%
  rename(tc_l = l, 
         tc_ml = ml, 
         tc_h = h, 
         tc_conf = conf) %>% 
  select(-c(tc, type)) -> scenarios

# fetch LM params
scenarios %>% left_join(mappings[mappings$type == "lm",], 
                        by = c("lm" = "label")) %>%
  rename(lm_l = l, 
         lm_ml = ml, 
         lm_h = h, 
         lm_conf = conf) %>% 
  select(-c(lm, type)) -> scenarios
```

## Run Simulations

Run the simulations. We perform `r prettyNum(simulation_count, big.mark=",")`
simulations per threat scenario. After some light munging, a `results` object 
is returned with metadata (attributes on the object) to note the date when these 
simulations were peformed.

```{r run_simulations}
pb <- tkProgressBar(title = "Evaluator simulations", 
                    label = "Working on simulation ",
                    min = 1, max = nrow(scenarios), initial = 1)

results <- by_row(scenarios, function(x) {
  #info <- sprintf("%d%% done", round(i))
  setTkProgressBar(pb, x$scenario_id, 
                   label = sprintf("Running scenario %s of %s", 
                                   x$scenario_id, nrow(scenarios)))
  calculate_ale(scenario = x,
                diff_estimates = control_params[[as.character(x$scenario_id)]],
                n = simulation_count,
                title = x$scenario_id,
                verbose = FALSE)},
  .labels = FALSE, .collate = "rows"
)

close(pb)
results %<>% select(-`.row`)
```

```{r tidy_results}
# convert title back to scenario_id
results <- results %>% mutate(title = as.integer(title)) %>% 
  rename(scenario_id = title)

# add the domain_id column
results %>% left_join(select(scenarios, c(scenario_id, domain_id)), 
                      by = c("scenario_id" = "scenario_id")) %>% View

# calculate the vuln percentage
# note that for no threat events, we report a NA vuln value
results <- results %>% mutate(vuln = 1 - (threat_events - loss_events) /
                                threat_events, 
                              vuln = ifelse(vuln < 0, 0, vuln))

# store the date on which this simulation set was generated
attr(results, "generated_on") <- Sys.time()
# store how many simulations ran on each scenario
attr(results, "simulation_count") <- simulation_count
```

## Create summary views

Calculate summary statistics for each scenario, reducing all the individual 
simulations to descriptors.

```{r summarize_scenarios}
scenario_summary <- results %>% group_by(domain_id, scenario_id) %>% 
  summarise(
    loss_events_mean = mean(loss_events, na.rm = TRUE),
    loss_events_min = min(loss_events, na.rm = TRUE),
    loss_events_max = max(loss_events, na.rm = TRUE),
    loss_events_median = median(loss_events, na.rm = TRUE),
    ale_median = median(ale, na.rm = TRUE),
    ale_max = max(ale, na.rm = TRUE),
    ale_var = quantile(ale, 0.95),
    sle_mean = mean(sle_median, na.rm = TRUE),
    sle_median = median(sle_median, na.rm = TRUE),
    sle_max = max(sle_max, na.rm = TRUE),
    sle_min = min(sle_min, na.rm = TRUE),
    mean_tc_exceedance = sum(mean_tc_exceedance * loss_events) / sum(loss_events),
    mean_diff_exceedance = sum(mean_diff_exceedance * 
                                 (threat_events - loss_events)) / 
      sum(threat_events - loss_events),
    mean_vuln = mean(vuln, na.rm = TRUE)) %>%
  mutate(sle_median = ifelse(is.nan(sle_median), NA, sle_median)) %>%
  ungroup()

# calculate z-score for ALE VaR and assign outliers as >= 2 SD
scenario_summary %<>% mutate(ale_var_zscore = scale(ale_var), 
                             outlier = ale_var_zscore >= 2)
scenario_summary
```

Also aggregate all the scenarios in each domain to the total losses experienced 
in a single simulation, giving the total annual expected loss (ALE per 
domain + simulation).

```{r summarize_by_domain}
domain_summary <- results %>% group_by(domain_id, simulation) %>% 
  summarise(ale = sum(ale)) %>%
  left_join(domains, by = c("domain_id" = "domain_id"))
domain_summary
```

Save the detailed results (`results`), per-scenario summaries 
(`scenario_summary`), domain summaries (`domain_summary`), and the 
full scenarios with parameters (`scenarios_full`).

```{r save_data, eval=save_flag}
saveRDS(scenarios, file = "./data/scenarios_full.Rds")
saveRDS(results, file = "./data/simulation_results.Rds")
saveRDS(scenario_summary, file = "./data/scenario_summary.Rds")
saveRDS(domain_summary, file = "./data/domain_summary.Rds")
file.info(c("data/simulation_results.Rds", "data/scenario_summary.Rds", 
            "data/domain_summary.Rds", "data/scenarios_full.Rds"))
```